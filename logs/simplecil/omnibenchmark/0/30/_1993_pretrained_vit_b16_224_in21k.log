2023-10-13 11:20:03,670 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 11:20:03,670 [trainer.py] => prefix:  
2023-10-13 11:20:03,670 [trainer.py] => dataset: omnibenchmark
2023-10-13 11:20:03,670 [trainer.py] => memory_size: 0
2023-10-13 11:20:03,670 [trainer.py] => memory_per_class: 0
2023-10-13 11:20:03,670 [trainer.py] => fixed_memory: False
2023-10-13 11:20:03,670 [trainer.py] => shuffle: True
2023-10-13 11:20:03,670 [trainer.py] => init_cls: 30
2023-10-13 11:20:03,670 [trainer.py] => increment: 30
2023-10-13 11:20:03,670 [trainer.py] => model_name: simplecil
2023-10-13 11:20:03,670 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 11:20:03,670 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 11:20:03,670 [trainer.py] => seed: 1993
2023-10-13 11:20:03,670 [trainer.py] => tuned_epoch: 0
2023-10-13 11:20:03,670 [trainer.py] => init_lr: 0.01
2023-10-13 11:20:03,670 [trainer.py] => batch_size: 256
2023-10-13 11:20:03,670 [trainer.py] => weight_decay: 0.05
2023-10-13 11:20:03,670 [trainer.py] => min_lr: 1e-08
2023-10-13 11:20:03,670 [trainer.py] => optimizer: sgd
2023-10-13 11:20:03,670 [trainer.py] => vpt_type: shallow
2023-10-13 11:20:03,670 [trainer.py] => prompt_token_num: 3
2023-10-13 11:20:03,997 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 11:20:57,569 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 11:20:57,569 [trainer.py] => prefix:  
2023-10-13 11:20:57,569 [trainer.py] => dataset: omnibenchmark
2023-10-13 11:20:57,569 [trainer.py] => memory_size: 0
2023-10-13 11:20:57,569 [trainer.py] => memory_per_class: 0
2023-10-13 11:20:57,569 [trainer.py] => fixed_memory: False
2023-10-13 11:20:57,569 [trainer.py] => shuffle: True
2023-10-13 11:20:57,569 [trainer.py] => init_cls: 30
2023-10-13 11:20:57,569 [trainer.py] => increment: 30
2023-10-13 11:20:57,569 [trainer.py] => model_name: simplecil
2023-10-13 11:20:57,569 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 11:20:57,569 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 11:20:57,569 [trainer.py] => seed: 1993
2023-10-13 11:20:57,569 [trainer.py] => tuned_epoch: 0
2023-10-13 11:20:57,569 [trainer.py] => init_lr: 0.01
2023-10-13 11:20:57,569 [trainer.py] => batch_size: 256
2023-10-13 11:20:57,569 [trainer.py] => weight_decay: 0.05
2023-10-13 11:20:57,569 [trainer.py] => min_lr: 1e-08
2023-10-13 11:20:57,569 [trainer.py] => optimizer: sgd
2023-10-13 11:20:57,569 [trainer.py] => vpt_type: shallow
2023-10-13 11:20:57,578 [trainer.py] => prompt_token_num: 3
2023-10-13 11:20:57,842 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 11:21:00,054 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 11:21:06,323 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 11:21:07,327 [trainer.py] => All params: 85798656
2023-10-13 11:21:07,346 [trainer.py] => Trainable params: 85798656
2023-10-13 11:21:08,074 [simplecil.py] => Learning on 0-30
2023-10-13 11:23:39,400 [trainer.py] => No NME accuracy.
2023-10-13 11:23:39,400 [trainer.py] => CNN: {'total': 87.33, '00-09': 91.0, '10-19': 88.0, '20-29': 83.0, 'old': 0, 'new': 87.33}
2023-10-13 11:23:39,400 [trainer.py] => CNN top1 curve: [87.33]
2023-10-13 11:23:39,400 [trainer.py] => CNN top5 curve: [98.67]

2023-10-13 11:23:39,415 [trainer.py] => Average Accuracy (CNN): 87.33
2023-10-13 11:23:39,431 [trainer.py] => All params: 85821697
2023-10-13 11:23:39,432 [trainer.py] => Trainable params: 85821697
2023-10-13 11:23:39,443 [simplecil.py] => Learning on 30-60
2023-10-13 11:26:20,482 [trainer.py] => No NME accuracy.
2023-10-13 11:26:20,482 [trainer.py] => CNN: {'total': 87.82, '00-09': 86.0, '10-19': 88.0, '20-29': 80.0, '30-39': 90.5, '40-49': 87.5, '50-59': 94.97, 'old': 84.67, 'new': 90.98}
2023-10-13 11:26:20,483 [trainer.py] => CNN top1 curve: [87.33, 87.82]
2023-10-13 11:26:20,483 [trainer.py] => CNN top5 curve: [98.67, 97.91]

2023-10-13 11:26:20,483 [trainer.py] => Average Accuracy (CNN): 87.57499999999999
2023-10-13 11:26:20,484 [trainer.py] => All params: 85844737
2023-10-13 11:26:20,484 [trainer.py] => Trainable params: 85844737
2023-10-13 11:26:20,485 [simplecil.py] => Learning on 60-90
2023-10-13 11:30:59,933 [trainer.py] => No NME accuracy.
2023-10-13 11:30:59,951 [trainer.py] => CNN: {'total': 84.98, '00-09': 82.0, '10-19': 83.0, '20-29': 75.5, '30-39': 87.0, '40-49': 86.0, '50-59': 92.96, '60-69': 91.5, '70-79': 88.0, '80-89': 78.89, 'old': 84.4, 'new': 86.14}
2023-10-13 11:30:59,951 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98]
2023-10-13 11:30:59,951 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0]

2023-10-13 11:30:59,964 [trainer.py] => Average Accuracy (CNN): 86.71
2023-10-13 11:30:59,969 [trainer.py] => All params: 85867777
2023-10-13 11:30:59,969 [trainer.py] => Trainable params: 85867777
2023-10-13 11:31:00,016 [simplecil.py] => Learning on 90-120
2023-10-13 11:34:18,813 [trainer.py] => No NME accuracy.
2023-10-13 11:34:18,828 [trainer.py] => CNN: {'total': 81.25, '00-09': 80.0, '10-19': 79.5, '20-29': 74.0, '30-39': 85.5, '40-49': 85.0, '50-59': 84.42, '60-69': 87.5, '70-79': 86.0, '80-89': 75.88, '90-99': 79.4, '100-109': 78.89, '110-119': 78.89, 'old': 81.98, 'new': 79.06}
2023-10-13 11:34:18,828 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25]
2023-10-13 11:34:18,828 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82]

2023-10-13 11:34:18,844 [trainer.py] => Average Accuracy (CNN): 85.345
2023-10-13 11:34:18,844 [trainer.py] => All params: 85890817
2023-10-13 11:34:18,844 [trainer.py] => Trainable params: 85890817
2023-10-13 11:34:18,860 [simplecil.py] => Learning on 120-150
2023-10-13 11:37:19,066 [trainer.py] => No NME accuracy.
2023-10-13 11:37:19,066 [trainer.py] => CNN: {'total': 79.26, '00-09': 76.5, '10-19': 80.0, '20-29': 73.0, '30-39': 85.0, '40-49': 81.5, '50-59': 79.4, '60-69': 83.5, '70-79': 85.0, '80-89': 73.87, '90-99': 78.39, '100-109': 76.88, '110-119': 71.86, '120-129': 84.0, '130-139': 80.0, '140-149': 79.9, 'old': 78.75, 'new': 81.3}
2023-10-13 11:37:19,067 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26]
2023-10-13 11:37:19,067 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69]

2023-10-13 11:37:19,068 [trainer.py] => Average Accuracy (CNN): 84.128
2023-10-13 11:37:19,068 [trainer.py] => All params: 85913857
2023-10-13 11:37:19,070 [trainer.py] => Trainable params: 85913857
2023-10-13 11:37:19,074 [simplecil.py] => Learning on 150-180
2023-10-13 11:40:25,448 [trainer.py] => No NME accuracy.
2023-10-13 11:40:25,448 [trainer.py] => CNN: {'total': 76.75, '00-09': 75.0, '10-19': 77.5, '20-29': 70.5, '30-39': 82.0, '40-49': 78.0, '50-59': 77.89, '60-69': 82.0, '70-79': 83.0, '80-89': 70.85, '90-99': 78.39, '100-109': 74.37, '110-119': 71.36, '120-129': 83.5, '130-139': 79.0, '140-149': 77.39, '150-159': 80.4, '160-169': 74.87, '170-179': 65.5, 'old': 77.39, 'new': 73.58}
2023-10-13 11:40:25,448 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26, 76.75]
2023-10-13 11:40:25,448 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69, 93.35]

2023-10-13 11:40:25,448 [trainer.py] => Average Accuracy (CNN): 82.89833333333333
2023-10-13 11:40:25,460 [trainer.py] => All params: 85936897
2023-10-13 11:40:25,460 [trainer.py] => Trainable params: 85936897
2023-10-13 11:40:25,468 [simplecil.py] => Learning on 180-210
2023-10-13 11:43:31,945 [trainer.py] => No NME accuracy.
2023-10-13 11:43:31,945 [trainer.py] => CNN: {'total': 75.53, '00-09': 73.0, '10-19': 76.5, '20-29': 70.0, '30-39': 83.5, '40-49': 78.0, '50-59': 76.88, '60-69': 79.0, '70-79': 82.5, '80-89': 70.85, '90-99': 75.88, '100-109': 74.37, '110-119': 66.83, '120-129': 84.0, '130-139': 78.5, '140-149': 75.88, '150-159': 76.88, '160-169': 72.36, '170-179': 66.5, '180-189': 71.72, '190-199': 82.5, '200-209': 70.35, 'old': 75.64, 'new': 74.87}
2023-10-13 11:43:31,945 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26, 76.75, 75.53]
2023-10-13 11:43:31,945 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69, 93.35, 92.77]

2023-10-13 11:43:31,945 [trainer.py] => Average Accuracy (CNN): 81.84571428571428
2023-10-13 11:43:31,945 [trainer.py] => All params: 85959937
2023-10-13 11:43:31,945 [trainer.py] => Trainable params: 85959937
2023-10-13 11:43:31,945 [simplecil.py] => Learning on 210-240
2023-10-13 11:46:58,914 [trainer.py] => No NME accuracy.
2023-10-13 11:46:58,915 [trainer.py] => CNN: {'total': 74.21, '00-09': 72.5, '10-19': 74.0, '20-29': 69.5, '30-39': 83.0, '40-49': 74.0, '50-59': 77.39, '60-69': 79.0, '70-79': 83.5, '80-89': 70.85, '90-99': 76.38, '100-109': 67.84, '110-119': 66.33, '120-129': 82.5, '130-139': 78.0, '140-149': 74.87, '150-159': 76.88, '160-169': 71.86, '170-179': 64.0, '180-189': 71.72, '190-199': 82.5, '200-209': 67.84, '210-219': 50.5, '220-229': 86.93, '230-239': 79.0, 'old': 74.5, 'new': 72.12}
2023-10-13 11:46:58,916 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26, 76.75, 75.53, 74.21]
2023-10-13 11:46:58,916 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69, 93.35, 92.77, 91.12]

2023-10-13 11:46:58,916 [trainer.py] => Average Accuracy (CNN): 80.89125
2023-10-13 11:46:58,917 [trainer.py] => All params: 85982977
2023-10-13 11:46:58,917 [trainer.py] => Trainable params: 85982977
2023-10-13 11:46:58,919 [simplecil.py] => Learning on 240-270
2023-10-13 11:50:29,699 [trainer.py] => No NME accuracy.
2023-10-13 11:50:29,699 [trainer.py] => CNN: {'total': 73.4, '00-09': 74.0, '10-19': 74.0, '20-29': 69.5, '30-39': 83.5, '40-49': 75.5, '50-59': 75.38, '60-69': 77.5, '70-79': 82.5, '80-89': 69.85, '90-99': 75.38, '100-109': 66.33, '110-119': 65.33, '120-129': 76.5, '130-139': 76.5, '140-149': 71.36, '150-159': 73.87, '160-169': 72.86, '170-179': 63.5, '180-189': 71.21, '190-199': 81.5, '200-209': 63.82, '210-219': 51.0, '220-229': 85.93, '230-239': 79.5, '240-249': 68.0, '250-259': 75.88, '260-269': 81.5, 'old': 73.18, 'new': 75.13}
2023-10-13 11:50:29,699 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26, 76.75, 75.53, 74.21, 73.4]
2023-10-13 11:50:29,699 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69, 93.35, 92.77, 91.12, 91.22]

2023-10-13 11:50:29,699 [trainer.py] => Average Accuracy (CNN): 80.05888888888889
2023-10-13 11:50:29,699 [trainer.py] => All params: 86006017
2023-10-13 11:50:29,699 [trainer.py] => Trainable params: 86006017
2023-10-13 11:50:29,699 [simplecil.py] => Learning on 270-300
2023-10-13 11:53:57,812 [trainer.py] => No NME accuracy.
2023-10-13 11:53:57,812 [trainer.py] => CNN: {'total': 73.37, '00-09': 72.0, '10-19': 74.5, '20-29': 68.5, '30-39': 83.0, '40-49': 72.0, '50-59': 75.88, '60-69': 76.5, '70-79': 82.0, '80-89': 70.35, '90-99': 71.36, '100-109': 64.82, '110-119': 61.81, '120-129': 78.0, '130-139': 77.0, '140-149': 73.37, '150-159': 73.37, '160-169': 71.36, '170-179': 63.0, '180-189': 70.71, '190-199': 80.5, '200-209': 64.82, '210-219': 49.5, '220-229': 85.43, '230-239': 79.5, '240-249': 65.0, '250-259': 76.38, '260-269': 80.5, '270-279': 77.39, '280-289': 83.0, '290-299': 79.4, 'old': 72.64, 'new': 79.93}
2023-10-13 11:53:57,812 [trainer.py] => CNN top1 curve: [87.33, 87.82, 84.98, 81.25, 79.26, 76.75, 75.53, 74.21, 73.4, 73.37]
2023-10-13 11:53:57,812 [trainer.py] => CNN top5 curve: [98.67, 97.91, 97.0, 95.82, 94.69, 93.35, 92.77, 91.12, 91.22, 91.35]

2023-10-13 11:53:57,812 [trainer.py] => Average Accuracy (CNN): 79.39
2023-10-13 11:57:04,184 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 11:57:04,184 [trainer.py] => prefix:  
2023-10-13 11:57:04,184 [trainer.py] => dataset: omnibenchmark
2023-10-13 11:57:04,184 [trainer.py] => memory_size: 0
2023-10-13 11:57:04,184 [trainer.py] => memory_per_class: 0
2023-10-13 11:57:04,184 [trainer.py] => fixed_memory: False
2023-10-13 11:57:04,184 [trainer.py] => shuffle: True
2023-10-13 11:57:04,184 [trainer.py] => init_cls: 30
2023-10-13 11:57:04,184 [trainer.py] => increment: 30
2023-10-13 11:57:04,184 [trainer.py] => model_name: simplecil
2023-10-13 11:57:04,184 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 11:57:04,184 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 11:57:04,184 [trainer.py] => seed: 1993
2023-10-13 11:57:04,184 [trainer.py] => tuned_epoch: 0
2023-10-13 11:57:04,184 [trainer.py] => init_lr: 0.01
2023-10-13 11:57:04,184 [trainer.py] => batch_size: 256
2023-10-13 11:57:04,184 [trainer.py] => weight_decay: 0.05
2023-10-13 11:57:04,184 [trainer.py] => min_lr: 1e-08
2023-10-13 11:57:04,184 [trainer.py] => optimizer: sgd
2023-10-13 11:57:04,184 [trainer.py] => vpt_type: shallow
2023-10-13 11:57:04,184 [trainer.py] => prompt_token_num: 3
2023-10-13 11:57:04,551 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 11:57:06,707 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 11:57:08,278 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 11:57:08,997 [trainer.py] => All params: 85798656
2023-10-13 11:57:08,997 [trainer.py] => Trainable params: 85798656
2023-10-13 11:57:09,381 [simplecil.py] => Learning on 0-30
2023-10-13 11:59:51,814 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 11:59:51,814 [trainer.py] => prefix:  
2023-10-13 11:59:51,814 [trainer.py] => dataset: omnibenchmark
2023-10-13 11:59:51,814 [trainer.py] => memory_size: 0
2023-10-13 11:59:51,814 [trainer.py] => memory_per_class: 0
2023-10-13 11:59:51,814 [trainer.py] => fixed_memory: False
2023-10-13 11:59:51,814 [trainer.py] => shuffle: True
2023-10-13 11:59:51,814 [trainer.py] => init_cls: 30
2023-10-13 11:59:51,814 [trainer.py] => increment: 30
2023-10-13 11:59:51,814 [trainer.py] => model_name: simplecil
2023-10-13 11:59:51,814 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 11:59:51,814 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 11:59:51,814 [trainer.py] => seed: 1993
2023-10-13 11:59:51,814 [trainer.py] => tuned_epoch: 0
2023-10-13 11:59:51,814 [trainer.py] => init_lr: 0.01
2023-10-13 11:59:51,814 [trainer.py] => batch_size: 256
2023-10-13 11:59:51,814 [trainer.py] => weight_decay: 0.05
2023-10-13 11:59:51,814 [trainer.py] => min_lr: 1e-08
2023-10-13 11:59:51,814 [trainer.py] => optimizer: sgd
2023-10-13 11:59:51,830 [trainer.py] => vpt_type: shallow
2023-10-13 11:59:51,830 [trainer.py] => prompt_token_num: 3
2023-10-13 11:59:52,079 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 11:59:53,555 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 11:59:53,906 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 11:59:54,025 [trainer.py] => All params: 85798656
2023-10-13 11:59:54,025 [trainer.py] => Trainable params: 85798656
2023-10-13 11:59:54,156 [simplecil.py] => Learning on 0-30
2023-10-13 12:30:02,387 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 12:30:02,387 [trainer.py] => prefix:  
2023-10-13 12:30:02,387 [trainer.py] => dataset: omnibenchmark
2023-10-13 12:30:02,387 [trainer.py] => memory_size: 0
2023-10-13 12:30:02,387 [trainer.py] => memory_per_class: 0
2023-10-13 12:30:02,387 [trainer.py] => fixed_memory: False
2023-10-13 12:30:02,387 [trainer.py] => shuffle: True
2023-10-13 12:30:02,387 [trainer.py] => init_cls: 30
2023-10-13 12:30:02,387 [trainer.py] => increment: 30
2023-10-13 12:30:02,387 [trainer.py] => model_name: simplecil
2023-10-13 12:30:02,387 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 12:30:02,387 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 12:30:02,387 [trainer.py] => seed: 1993
2023-10-13 12:30:02,387 [trainer.py] => tuned_epoch: 0
2023-10-13 12:30:02,387 [trainer.py] => init_lr: 0.01
2023-10-13 12:30:02,387 [trainer.py] => batch_size: 256
2023-10-13 12:30:02,387 [trainer.py] => weight_decay: 0.05
2023-10-13 12:30:02,392 [trainer.py] => min_lr: 1e-08
2023-10-13 12:30:02,392 [trainer.py] => optimizer: sgd
2023-10-13 12:30:02,392 [trainer.py] => vpt_type: shallow
2023-10-13 12:30:02,392 [trainer.py] => prompt_token_num: 3
2023-10-13 12:30:02,696 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 12:30:04,028 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 12:30:04,365 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 12:30:04,503 [trainer.py] => All params: 85798656
2023-10-13 12:30:04,503 [trainer.py] => Trainable params: 85798656
2023-10-13 12:30:04,628 [simplecil.py] => Learning on 0-30
2023-10-13 12:33:57,415 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 12:33:57,415 [trainer.py] => prefix:  
2023-10-13 12:33:57,415 [trainer.py] => dataset: omnibenchmark
2023-10-13 12:33:57,415 [trainer.py] => memory_size: 0
2023-10-13 12:33:57,415 [trainer.py] => memory_per_class: 0
2023-10-13 12:33:57,415 [trainer.py] => fixed_memory: False
2023-10-13 12:33:57,415 [trainer.py] => shuffle: True
2023-10-13 12:33:57,415 [trainer.py] => init_cls: 30
2023-10-13 12:33:57,415 [trainer.py] => increment: 30
2023-10-13 12:33:57,415 [trainer.py] => model_name: simplecil
2023-10-13 12:33:57,415 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 12:33:57,415 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 12:33:57,415 [trainer.py] => seed: 1993
2023-10-13 12:33:57,415 [trainer.py] => tuned_epoch: 0
2023-10-13 12:33:57,415 [trainer.py] => init_lr: 0.01
2023-10-13 12:33:57,415 [trainer.py] => batch_size: 256
2023-10-13 12:33:57,415 [trainer.py] => weight_decay: 0.05
2023-10-13 12:33:57,415 [trainer.py] => min_lr: 1e-08
2023-10-13 12:33:57,415 [trainer.py] => optimizer: sgd
2023-10-13 12:33:57,415 [trainer.py] => vpt_type: shallow
2023-10-13 12:33:57,415 [trainer.py] => prompt_token_num: 3
2023-10-13 12:33:57,750 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 12:33:59,227 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 12:33:59,646 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 12:33:59,815 [trainer.py] => All params: 85798656
2023-10-13 12:33:59,815 [trainer.py] => Trainable params: 85798656
2023-10-13 12:33:59,973 [simplecil.py] => Learning on 0-30
2023-10-13 12:35:24,549 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 12:35:24,549 [trainer.py] => prefix:  
2023-10-13 12:35:24,549 [trainer.py] => dataset: omnibenchmark
2023-10-13 12:35:24,549 [trainer.py] => memory_size: 0
2023-10-13 12:35:24,549 [trainer.py] => memory_per_class: 0
2023-10-13 12:35:24,549 [trainer.py] => fixed_memory: False
2023-10-13 12:35:24,549 [trainer.py] => shuffle: True
2023-10-13 12:35:24,555 [trainer.py] => init_cls: 30
2023-10-13 12:35:24,555 [trainer.py] => increment: 30
2023-10-13 12:35:24,555 [trainer.py] => model_name: simplecil
2023-10-13 12:35:24,555 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 12:35:24,555 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 12:35:24,555 [trainer.py] => seed: 1993
2023-10-13 12:35:24,555 [trainer.py] => tuned_epoch: 0
2023-10-13 12:35:24,555 [trainer.py] => init_lr: 0.01
2023-10-13 12:35:24,555 [trainer.py] => batch_size: 256
2023-10-13 12:35:24,555 [trainer.py] => weight_decay: 0.05
2023-10-13 12:35:24,555 [trainer.py] => min_lr: 1e-08
2023-10-13 12:35:24,555 [trainer.py] => optimizer: sgd
2023-10-13 12:35:24,555 [trainer.py] => vpt_type: shallow
2023-10-13 12:35:24,555 [trainer.py] => prompt_token_num: 3
2023-10-13 12:35:24,852 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 12:35:26,131 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 12:35:26,484 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 12:35:26,636 [trainer.py] => All params: 85798656
2023-10-13 12:35:26,636 [trainer.py] => Trainable params: 85798656
2023-10-13 12:35:26,755 [simplecil.py] => Learning on 0-30
2023-10-13 12:38:01,452 [trainer.py] => No NME accuracy.
2023-10-13 12:38:01,452 [trainer.py] => CNN: {'total': 82.17, '00-09': 84.5, '10-19': 83.5, '20-29': 78.5, 'old': 0, 'new': 82.17}
2023-10-13 12:38:01,452 [trainer.py] => CNN top1 curve: [82.17]
2023-10-13 12:38:01,452 [trainer.py] => CNN top5 curve: [97.67]

2023-10-13 12:38:01,453 [trainer.py] => Average Accuracy (CNN): 82.17
2023-10-13 12:38:01,453 [trainer.py] => All params: 85821697
2023-10-13 12:38:01,454 [trainer.py] => Trainable params: 85821697
2023-10-13 12:38:01,485 [simplecil.py] => Learning on 30-60
2023-10-13 12:40:44,749 [trainer.py] => No NME accuracy.
2023-10-13 12:40:44,749 [trainer.py] => CNN: {'total': 40.45, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 71.0, '40-49': 79.5, '50-59': 92.46, 'old': 0.0, 'new': 80.97}
2023-10-13 12:40:44,749 [trainer.py] => CNN top1 curve: [82.17, 40.45]
2023-10-13 12:40:44,749 [trainer.py] => CNN top5 curve: [97.67, 47.29]

2023-10-13 12:40:44,749 [trainer.py] => Average Accuracy (CNN): 61.31
2023-10-13 12:40:44,749 [trainer.py] => All params: 85844737
2023-10-13 12:40:44,749 [trainer.py] => Trainable params: 85844737
2023-10-13 12:40:44,754 [simplecil.py] => Learning on 60-90
2023-10-13 12:43:34,649 [trainer.py] => No NME accuracy.
2023-10-13 12:43:34,649 [trainer.py] => CNN: {'total': 27.75, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 91.5, '70-79': 82.5, '80-89': 75.88, 'old': 0.0, 'new': 83.31}
2023-10-13 12:43:34,649 [trainer.py] => CNN top1 curve: [82.17, 40.45, 27.75]
2023-10-13 12:43:34,649 [trainer.py] => CNN top5 curve: [97.67, 47.29, 31.92]

2023-10-13 12:43:34,649 [trainer.py] => Average Accuracy (CNN): 50.123333333333335
2023-10-13 12:43:34,649 [trainer.py] => All params: 85867777
2023-10-13 12:43:34,649 [trainer.py] => Trainable params: 85867777
2023-10-13 12:43:34,649 [simplecil.py] => Learning on 90-120
2023-10-13 12:46:35,546 [trainer.py] => No NME accuracy.
2023-10-13 12:46:35,546 [trainer.py] => CNN: {'total': 20.42, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 0.0, '70-79': 0.0, '80-89': 0.0, '90-99': 89.95, '100-109': 91.96, '110-119': 63.82, 'old': 0.0, 'new': 81.91}
2023-10-13 12:46:35,546 [trainer.py] => CNN top1 curve: [82.17, 40.45, 27.75, 20.42]
2023-10-13 12:46:35,546 [trainer.py] => CNN top5 curve: [97.67, 47.29, 31.92, 23.55]

2023-10-13 12:46:35,546 [trainer.py] => Average Accuracy (CNN): 42.697500000000005
2023-10-13 12:46:35,546 [trainer.py] => All params: 85890817
2023-10-13 12:46:35,552 [trainer.py] => Trainable params: 85890817
2023-10-13 12:46:35,553 [simplecil.py] => Learning on 120-150
2023-10-13 12:53:42,000 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 12:53:42,000 [trainer.py] => prefix:  
2023-10-13 12:53:42,000 [trainer.py] => dataset: omnibenchmark
2023-10-13 12:53:42,000 [trainer.py] => memory_size: 0
2023-10-13 12:53:42,000 [trainer.py] => memory_per_class: 0
2023-10-13 12:53:42,000 [trainer.py] => fixed_memory: False
2023-10-13 12:53:42,000 [trainer.py] => shuffle: True
2023-10-13 12:53:42,000 [trainer.py] => init_cls: 30
2023-10-13 12:53:42,000 [trainer.py] => increment: 30
2023-10-13 12:53:42,000 [trainer.py] => model_name: simplecil
2023-10-13 12:53:42,000 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 12:53:42,000 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 12:53:42,000 [trainer.py] => seed: 1993
2023-10-13 12:53:42,000 [trainer.py] => tuned_epoch: 0
2023-10-13 12:53:42,000 [trainer.py] => init_lr: 0.01
2023-10-13 12:53:42,000 [trainer.py] => batch_size: 256
2023-10-13 12:53:42,006 [trainer.py] => weight_decay: 0.05
2023-10-13 12:53:42,006 [trainer.py] => min_lr: 1e-08
2023-10-13 12:53:42,006 [trainer.py] => optimizer: sgd
2023-10-13 12:53:42,006 [trainer.py] => vpt_type: shallow
2023-10-13 12:53:42,006 [trainer.py] => prompt_token_num: 3
2023-10-13 12:53:42,642 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 12:53:44,112 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 12:53:44,473 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 12:53:45,113 [trainer.py] => All params: 85798656
2023-10-13 12:53:45,113 [trainer.py] => Trainable params: 85798656
2023-10-13 12:53:45,242 [simplecil.py] => Learning on 0-30
2023-10-13 12:56:19,100 [trainer.py] => No NME accuracy.
2023-10-13 12:56:19,100 [trainer.py] => CNN: {'total': 82.17, '00-09': 84.5, '10-19': 83.5, '20-29': 78.5, 'old': 0, 'new': 82.17}
2023-10-13 12:56:19,100 [trainer.py] => CNN top1 curve: [82.17]
2023-10-13 12:56:19,100 [trainer.py] => CNN top5 curve: [97.67]

2023-10-13 12:56:19,100 [trainer.py] => Average Accuracy (CNN): 82.17
2023-10-13 12:56:19,100 [trainer.py] => All params: 85821697
2023-10-13 12:56:19,100 [trainer.py] => Trainable params: 85821697
2023-10-13 12:56:19,132 [simplecil.py] => Learning on 30-60
2023-10-13 13:00:50,187 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 13:00:50,187 [trainer.py] => prefix:  
2023-10-13 13:00:50,187 [trainer.py] => dataset: omnibenchmark
2023-10-13 13:00:50,187 [trainer.py] => memory_size: 0
2023-10-13 13:00:50,187 [trainer.py] => memory_per_class: 0
2023-10-13 13:00:50,187 [trainer.py] => fixed_memory: False
2023-10-13 13:00:50,187 [trainer.py] => shuffle: True
2023-10-13 13:00:50,187 [trainer.py] => init_cls: 30
2023-10-13 13:00:50,187 [trainer.py] => increment: 30
2023-10-13 13:00:50,187 [trainer.py] => model_name: simplecil
2023-10-13 13:00:50,187 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 13:00:50,187 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 13:00:50,187 [trainer.py] => seed: 1993
2023-10-13 13:00:50,187 [trainer.py] => tuned_epoch: 0
2023-10-13 13:00:50,187 [trainer.py] => init_lr: 0.01
2023-10-13 13:00:50,187 [trainer.py] => batch_size: 256
2023-10-13 13:00:50,187 [trainer.py] => weight_decay: 0.05
2023-10-13 13:00:50,187 [trainer.py] => min_lr: 1e-08
2023-10-13 13:00:50,187 [trainer.py] => optimizer: sgd
2023-10-13 13:00:50,187 [trainer.py] => vpt_type: shallow
2023-10-13 13:00:50,187 [trainer.py] => prompt_token_num: 3
2023-10-13 13:00:50,478 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 13:00:51,769 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 13:00:52,102 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 13:00:52,229 [trainer.py] => All params: 85798656
2023-10-13 13:00:52,229 [trainer.py] => Trainable params: 85798656
2023-10-13 13:00:52,356 [simplecil.py] => Learning on 0-30
2023-10-13 13:12:13,328 [trainer.py] => No NME accuracy.
2023-10-13 13:12:13,328 [trainer.py] => CNN: {'total': 27.17, '00-09': 21.5, '10-19': 35.0, '20-29': 25.0, 'old': 0, 'new': 27.17}
2023-10-13 13:12:13,328 [trainer.py] => CNN top1 curve: [27.17]
2023-10-13 13:12:13,328 [trainer.py] => CNN top5 curve: [63.17]

2023-10-13 13:12:13,353 [trainer.py] => Average Accuracy (CNN): 27.17
2023-10-13 13:12:13,355 [trainer.py] => All params: 85821697
2023-10-13 13:12:13,356 [trainer.py] => Trainable params: 85821697
2023-10-13 13:12:13,365 [simplecil.py] => Learning on 30-60
2023-10-13 13:23:58,503 [trainer.py] => No NME accuracy.
2023-10-13 13:23:58,503 [trainer.py] => CNN: {'total': 43.29, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 84.5, '40-49': 93.5, '50-59': 81.91, 'old': 0.0, 'new': 86.64}
2023-10-13 13:23:58,504 [trainer.py] => CNN top1 curve: [27.17, 43.29]
2023-10-13 13:23:58,504 [trainer.py] => CNN top5 curve: [63.17, 49.12]

2023-10-13 13:23:58,504 [trainer.py] => Average Accuracy (CNN): 35.230000000000004
2023-10-13 13:23:58,505 [trainer.py] => All params: 85844737
2023-10-13 13:23:58,505 [trainer.py] => Trainable params: 85844737
2023-10-13 13:23:58,507 [simplecil.py] => Learning on 60-90
2023-10-13 13:35:52,299 [trainer.py] => No NME accuracy.
2023-10-13 13:35:52,300 [trainer.py] => CNN: {'total': 54.84, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 79.5, '40-49': 81.5, '50-59': 76.88, '60-69': 84.5, '70-79': 88.5, '80-89': 82.91, 'old': 39.62, 'new': 85.31}
2023-10-13 13:35:52,301 [trainer.py] => CNN top1 curve: [27.17, 43.29, 54.84]
2023-10-13 13:35:52,301 [trainer.py] => CNN top5 curve: [63.17, 49.12, 64.79]

2023-10-13 13:35:52,301 [trainer.py] => Average Accuracy (CNN): 41.76666666666667
2023-10-13 13:35:52,302 [trainer.py] => All params: 85867777
2023-10-13 13:35:52,302 [trainer.py] => Trainable params: 85867777
2023-10-13 13:35:52,304 [simplecil.py] => Learning on 90-120
2023-10-13 13:47:58,099 [trainer.py] => No NME accuracy.
2023-10-13 13:47:58,100 [trainer.py] => CNN: {'total': 57.91, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 73.5, '40-49': 76.5, '50-59': 73.87, '60-69': 67.0, '70-79': 80.0, '80-89': 74.87, '90-99': 85.93, '100-109': 84.92, '110-119': 78.89, 'old': 49.5, 'new': 83.25}
2023-10-13 13:47:58,100 [trainer.py] => CNN top1 curve: [27.17, 43.29, 54.84, 57.91]
2023-10-13 13:47:58,100 [trainer.py] => CNN top5 curve: [63.17, 49.12, 64.79, 70.9]

2023-10-13 13:47:58,101 [trainer.py] => Average Accuracy (CNN): 45.8025
2023-10-13 13:47:58,101 [trainer.py] => All params: 85890817
2023-10-13 13:47:58,102 [trainer.py] => Trainable params: 85890817
2023-10-13 13:47:58,105 [simplecil.py] => Learning on 120-150
2023-10-13 14:00:10,037 [trainer.py] => No NME accuracy.
2023-10-13 14:00:10,039 [trainer.py] => CNN: {'total': 59.19, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 71.5, '40-49': 72.5, '50-59': 61.31, '60-69': 63.0, '70-79': 78.0, '80-89': 69.85, '90-99': 84.92, '100-109': 77.89, '110-119': 70.35, '120-129': 84.0, '130-139': 78.0, '140-149': 76.88, 'old': 54.07, 'new': 79.63}
2023-10-13 14:00:10,040 [trainer.py] => CNN top1 curve: [27.17, 43.29, 54.84, 57.91, 59.19]
2023-10-13 14:00:10,041 [trainer.py] => CNN top5 curve: [63.17, 49.12, 64.79, 70.9, 73.75]

2023-10-13 14:00:10,041 [trainer.py] => Average Accuracy (CNN): 48.480000000000004
2023-10-13 14:00:10,043 [trainer.py] => All params: 85913857
2023-10-13 14:00:10,043 [trainer.py] => Trainable params: 85913857
2023-10-13 14:00:10,048 [simplecil.py] => Learning on 150-180
2023-10-13 14:12:08,648 [trainer.py] => No NME accuracy.
2023-10-13 14:12:08,648 [trainer.py] => CNN: {'total': 59.33, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 69.0, '40-49': 67.5, '50-59': 58.79, '60-69': 63.0, '70-79': 76.0, '80-89': 67.84, '90-99': 83.92, '100-109': 75.88, '110-119': 63.32, '120-129': 82.0, '130-139': 77.0, '140-149': 72.36, '150-159': 79.9, '160-169': 68.34, '170-179': 63.5, 'old': 57.08, 'new': 70.57}
2023-10-13 14:12:08,648 [trainer.py] => CNN top1 curve: [27.17, 43.29, 54.84, 57.91, 59.19, 59.33]
2023-10-13 14:12:08,648 [trainer.py] => CNN top5 curve: [63.17, 49.12, 64.79, 70.9, 73.75, 75.28]

2023-10-13 14:12:08,648 [trainer.py] => Average Accuracy (CNN): 50.288333333333334
2023-10-13 14:12:08,648 [trainer.py] => All params: 85936897
2023-10-13 14:12:08,648 [trainer.py] => Trainable params: 85936897
2023-10-13 14:12:08,648 [simplecil.py] => Learning on 180-210
2023-10-13 14:24:15,769 [trainer.py] => No NME accuracy.
2023-10-13 14:24:15,769 [trainer.py] => CNN: {'total': 59.68, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 67.0, '40-49': 67.0, '50-59': 58.79, '60-69': 59.5, '70-79': 71.0, '80-89': 64.82, '90-99': 80.9, '100-109': 74.37, '110-119': 53.27, '120-129': 79.0, '130-139': 75.5, '140-149': 71.86, '150-159': 77.89, '160-169': 67.34, '170-179': 62.5, '180-189': 72.73, '190-199': 81.0, '200-209': 69.35, 'old': 57.24, 'new': 74.37}
2023-10-13 14:24:15,769 [trainer.py] => CNN top1 curve: [27.17, 43.29, 54.84, 57.91, 59.19, 59.33, 59.68]
2023-10-13 14:24:15,769 [trainer.py] => CNN top5 curve: [63.17, 49.12, 64.79, 70.9, 73.75, 75.28, 76.34]

2023-10-13 14:24:15,769 [trainer.py] => Average Accuracy (CNN): 51.63
2023-10-13 14:24:15,769 [trainer.py] => All params: 85959937
2023-10-13 14:24:15,769 [trainer.py] => Trainable params: 85959937
2023-10-13 14:24:15,769 [simplecil.py] => Learning on 210-240
2023-10-13 14:27:16,699 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 14:27:16,699 [trainer.py] => prefix:  
2023-10-13 14:27:16,699 [trainer.py] => dataset: omnibenchmark
2023-10-13 14:27:16,699 [trainer.py] => memory_size: 0
2023-10-13 14:27:16,699 [trainer.py] => memory_per_class: 0
2023-10-13 14:27:16,699 [trainer.py] => fixed_memory: False
2023-10-13 14:27:16,699 [trainer.py] => shuffle: True
2023-10-13 14:27:16,699 [trainer.py] => init_cls: 30
2023-10-13 14:27:16,699 [trainer.py] => increment: 30
2023-10-13 14:27:16,699 [trainer.py] => model_name: simplecil
2023-10-13 14:27:16,699 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 14:27:16,699 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 14:27:16,699 [trainer.py] => seed: 1993
2023-10-13 14:27:16,699 [trainer.py] => tuned_epoch: 0
2023-10-13 14:27:16,699 [trainer.py] => init_lr: 0.01
2023-10-13 14:27:16,699 [trainer.py] => batch_size: 256
2023-10-13 14:27:16,699 [trainer.py] => weight_decay: 0.05
2023-10-13 14:27:16,699 [trainer.py] => min_lr: 1e-08
2023-10-13 14:27:16,699 [trainer.py] => optimizer: sgd
2023-10-13 14:27:16,699 [trainer.py] => vpt_type: shallow
2023-10-13 14:27:16,699 [trainer.py] => prompt_token_num: 3
2023-10-13 14:27:17,393 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 14:27:18,884 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 14:27:19,373 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 14:27:20,001 [trainer.py] => All params: 85798656
2023-10-13 14:27:20,001 [trainer.py] => Trainable params: 85798656
2023-10-13 14:27:20,206 [simplecil.py] => Learning on 0-30
2023-10-13 14:38:08,480 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 14:38:08,480 [trainer.py] => prefix:  
2023-10-13 14:38:08,480 [trainer.py] => dataset: omnibenchmark
2023-10-13 14:38:08,480 [trainer.py] => memory_size: 0
2023-10-13 14:38:08,480 [trainer.py] => memory_per_class: 0
2023-10-13 14:38:08,480 [trainer.py] => fixed_memory: False
2023-10-13 14:38:08,480 [trainer.py] => shuffle: True
2023-10-13 14:38:08,480 [trainer.py] => init_cls: 30
2023-10-13 14:38:08,480 [trainer.py] => increment: 30
2023-10-13 14:38:08,480 [trainer.py] => model_name: simplecil
2023-10-13 14:38:08,480 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 14:38:08,480 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 14:38:08,480 [trainer.py] => seed: 1993
2023-10-13 14:38:08,480 [trainer.py] => tuned_epoch: 0
2023-10-13 14:38:08,480 [trainer.py] => init_lr: 0.01
2023-10-13 14:38:08,480 [trainer.py] => batch_size: 256
2023-10-13 14:38:08,480 [trainer.py] => weight_decay: 0.05
2023-10-13 14:38:08,480 [trainer.py] => min_lr: 1e-08
2023-10-13 14:38:08,480 [trainer.py] => optimizer: sgd
2023-10-13 14:38:08,480 [trainer.py] => vpt_type: shallow
2023-10-13 14:38:08,480 [trainer.py] => prompt_token_num: 3
2023-10-13 14:38:08,737 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 14:38:09,957 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 14:38:10,301 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 14:38:10,408 [trainer.py] => All params: 85798656
2023-10-13 14:38:10,408 [trainer.py] => Trainable params: 85798656
2023-10-13 14:38:10,537 [simplecil.py] => Learning on 0-30
2023-10-13 14:45:46,210 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 14:45:46,210 [trainer.py] => prefix:  
2023-10-13 14:45:46,210 [trainer.py] => dataset: omnibenchmark
2023-10-13 14:45:46,210 [trainer.py] => memory_size: 0
2023-10-13 14:45:46,210 [trainer.py] => memory_per_class: 0
2023-10-13 14:45:46,211 [trainer.py] => fixed_memory: False
2023-10-13 14:45:46,211 [trainer.py] => shuffle: True
2023-10-13 14:45:46,211 [trainer.py] => init_cls: 30
2023-10-13 14:45:46,211 [trainer.py] => increment: 30
2023-10-13 14:45:46,211 [trainer.py] => model_name: simplecil
2023-10-13 14:45:46,211 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 14:45:46,212 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 14:45:46,212 [trainer.py] => seed: 1993
2023-10-13 14:45:46,212 [trainer.py] => tuned_epoch: 0
2023-10-13 14:45:46,212 [trainer.py] => init_lr: 0.01
2023-10-13 14:45:46,212 [trainer.py] => batch_size: 256
2023-10-13 14:45:46,212 [trainer.py] => weight_decay: 0.05
2023-10-13 14:45:46,212 [trainer.py] => min_lr: 1e-08
2023-10-13 14:45:46,213 [trainer.py] => optimizer: sgd
2023-10-13 14:45:46,213 [trainer.py] => vpt_type: shallow
2023-10-13 14:45:46,213 [trainer.py] => prompt_token_num: 3
2023-10-13 14:45:46,469 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 14:45:47,826 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 14:45:48,234 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 14:45:48,338 [trainer.py] => All params: 85798656
2023-10-13 14:45:48,338 [trainer.py] => Trainable params: 85798656
2023-10-13 14:45:48,493 [simplecil.py] => Learning on 0-30
2023-10-13 14:58:22,584 [trainer.py] => No NME accuracy.
2023-10-13 14:58:22,584 [trainer.py] => CNN: {'total': 26.33, '00-09': 20.5, '10-19': 34.0, '20-29': 24.5, 'old': 0, 'new': 26.33}
2023-10-13 14:58:22,584 [trainer.py] => CNN top1 curve: [26.33]
2023-10-13 14:58:22,584 [trainer.py] => CNN top5 curve: [63.67]

2023-10-13 14:58:22,628 [trainer.py] => Average Accuracy (CNN): 26.33
2023-10-13 14:58:22,629 [trainer.py] => All params: 85821697
2023-10-13 14:58:22,630 [trainer.py] => Trainable params: 85821697
2023-10-13 14:58:22,653 [simplecil.py] => Learning on 30-60
2023-10-13 15:11:50,087 [trainer.py] => No NME accuracy.
2023-10-13 15:11:50,087 [trainer.py] => CNN: {'total': 11.59, '00-09': 11.0, '10-19': 23.5, '20-29': 12.5, '30-39': 13.0, '40-49': 2.0, '50-59': 7.54, 'old': 15.67, 'new': 7.51}
2023-10-13 15:11:50,087 [trainer.py] => CNN top1 curve: [26.33, 11.59]
2023-10-13 15:11:50,087 [trainer.py] => CNN top5 curve: [63.67, 29.86]

2023-10-13 15:11:50,087 [trainer.py] => Average Accuracy (CNN): 18.96
2023-10-13 15:11:50,087 [trainer.py] => All params: 85844737
2023-10-13 15:11:50,087 [trainer.py] => Trainable params: 85844737
2023-10-13 15:11:50,087 [simplecil.py] => Learning on 60-90
2023-10-13 15:13:05,843 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-13 15:13:05,843 [trainer.py] => prefix:  
2023-10-13 15:13:05,843 [trainer.py] => dataset: omnibenchmark
2023-10-13 15:13:05,843 [trainer.py] => memory_size: 0
2023-10-13 15:13:05,843 [trainer.py] => memory_per_class: 0
2023-10-13 15:13:05,843 [trainer.py] => fixed_memory: False
2023-10-13 15:13:05,843 [trainer.py] => shuffle: True
2023-10-13 15:13:05,843 [trainer.py] => init_cls: 30
2023-10-13 15:13:05,843 [trainer.py] => increment: 30
2023-10-13 15:13:05,843 [trainer.py] => model_name: simplecil
2023-10-13 15:13:05,843 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-13 15:13:05,843 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-13 15:13:05,843 [trainer.py] => seed: 1993
2023-10-13 15:13:05,843 [trainer.py] => tuned_epoch: 0
2023-10-13 15:13:05,858 [trainer.py] => init_lr: 0.01
2023-10-13 15:13:05,858 [trainer.py] => batch_size: 256
2023-10-13 15:13:05,858 [trainer.py] => weight_decay: 0.05
2023-10-13 15:13:05,858 [trainer.py] => min_lr: 1e-08
2023-10-13 15:13:05,858 [trainer.py] => optimizer: sgd
2023-10-13 15:13:05,858 [trainer.py] => vpt_type: shallow
2023-10-13 15:13:05,858 [trainer.py] => prompt_token_num: 3
2023-10-13 15:13:06,520 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-13 15:13:07,992 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-13 15:13:08,452 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-13 15:13:09,101 [trainer.py] => All params: 85798656
2023-10-13 15:13:09,113 [trainer.py] => Trainable params: 85798656
2023-10-13 15:13:09,323 [simplecil.py] => Learning on 0-30
2023-10-13 15:37:32,222 [trainer.py] => No NME accuracy.
2023-10-13 15:37:32,222 [trainer.py] => CNN: {'total': 60.67, '00-09': 63.0, '10-19': 69.0, '20-29': 50.0, 'old': 0, 'new': 60.67}
2023-10-13 15:37:32,222 [trainer.py] => CNN top1 curve: [60.67]
2023-10-13 15:37:32,222 [trainer.py] => CNN top5 curve: [92.0]

2023-10-13 15:37:32,273 [trainer.py] => Average Accuracy (CNN): 60.67
2023-10-13 15:37:32,273 [trainer.py] => All params: 85821697
2023-10-13 15:37:32,273 [trainer.py] => Trainable params: 85821697
2023-10-13 15:37:32,293 [simplecil.py] => Learning on 30-60
2023-10-13 16:03:43,219 [trainer.py] => No NME accuracy.
2023-10-13 16:03:43,219 [trainer.py] => CNN: {'total': 26.94, '00-09': 44.0, '10-19': 43.0, '20-29': 34.0, '30-39': 25.5, '40-49': 3.0, '50-59': 12.06, 'old': 40.33, 'new': 13.52}
2023-10-13 16:03:43,219 [trainer.py] => CNN top1 curve: [60.67, 26.94]
2023-10-13 16:03:43,219 [trainer.py] => CNN top5 curve: [92.0, 50.63]

2023-10-13 16:03:43,219 [trainer.py] => Average Accuracy (CNN): 43.805
2023-10-13 16:03:43,219 [trainer.py] => All params: 85844737
2023-10-13 16:03:43,219 [trainer.py] => Trainable params: 85844737
2023-10-13 16:03:43,219 [simplecil.py] => Learning on 60-90
2023-10-16 00:11:44,638 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 00:11:44,638 [trainer.py] => prefix:  
2023-10-16 00:11:44,639 [trainer.py] => dataset: omnibenchmark
2023-10-16 00:11:44,639 [trainer.py] => memory_size: 0
2023-10-16 00:11:44,639 [trainer.py] => memory_per_class: 0
2023-10-16 00:11:44,639 [trainer.py] => fixed_memory: False
2023-10-16 00:11:44,639 [trainer.py] => shuffle: True
2023-10-16 00:11:44,640 [trainer.py] => init_cls: 30
2023-10-16 00:11:44,640 [trainer.py] => increment: 30
2023-10-16 00:11:44,640 [trainer.py] => model_name: simplecil
2023-10-16 00:11:44,640 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 00:11:44,640 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 00:11:44,640 [trainer.py] => seed: 1993
2023-10-16 00:11:44,640 [trainer.py] => tuned_epoch: 0
2023-10-16 00:11:44,640 [trainer.py] => init_lr: 0.01
2023-10-16 00:11:44,640 [trainer.py] => batch_size: 256
2023-10-16 00:11:44,641 [trainer.py] => weight_decay: 0.05
2023-10-16 00:11:44,641 [trainer.py] => min_lr: 1e-08
2023-10-16 00:11:44,641 [trainer.py] => optimizer: sgd
2023-10-16 00:11:44,641 [trainer.py] => vpt_type: shallow
2023-10-16 00:11:44,641 [trainer.py] => prompt_token_num: 3
2023-10-16 00:11:45,067 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 00:11:47,903 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 00:11:48,367 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 00:11:49,025 [trainer.py] => All params: 85798656
2023-10-16 00:11:49,025 [trainer.py] => Trainable params: 85798656
2023-10-16 00:11:49,632 [simplecil.py] => Learning on 0-30
2023-10-16 00:19:19,072 [trainer.py] => No NME accuracy.
2023-10-16 00:19:19,072 [trainer.py] => CNN: {'total': 87.5, '00-09': 91.0, '10-19': 89.0, '20-29': 82.5, 'old': 0, 'new': 87.5}
2023-10-16 00:19:19,072 [trainer.py] => CNN top1 curve: [87.5]
2023-10-16 00:19:19,072 [trainer.py] => CNN top5 curve: [98.83]

2023-10-16 00:19:19,072 [trainer.py] => Average Accuracy (CNN): 87.5
2023-10-16 00:19:19,072 [trainer.py] => All params: 85821697
2023-10-16 00:19:19,072 [trainer.py] => Trainable params: 85821697
2023-10-16 00:19:19,090 [simplecil.py] => Learning on 30-60
2023-10-16 00:27:30,233 [trainer.py] => No NME accuracy.
2023-10-16 00:27:30,233 [trainer.py] => CNN: {'total': 87.74, '00-09': 86.0, '10-19': 88.0, '20-29': 80.0, '30-39': 89.5, '40-49': 88.0, '50-59': 94.97, 'old': 84.67, 'new': 90.82}
2023-10-16 00:27:30,233 [trainer.py] => CNN top1 curve: [87.5, 87.74]
2023-10-16 00:27:30,233 [trainer.py] => CNN top5 curve: [98.83, 98.08]

2023-10-16 00:27:30,233 [trainer.py] => Average Accuracy (CNN): 87.62
2023-10-16 00:27:30,233 [trainer.py] => All params: 85844737
2023-10-16 00:27:30,233 [trainer.py] => Trainable params: 85844737
2023-10-16 00:27:30,233 [simplecil.py] => Learning on 60-90
2023-10-16 00:35:41,171 [trainer.py] => No NME accuracy.
2023-10-16 00:35:41,172 [trainer.py] => CNN: {'total': 84.87, '00-09': 81.0, '10-19': 83.0, '20-29': 76.5, '30-39': 87.0, '40-49': 86.0, '50-59': 92.46, '60-69': 91.5, '70-79': 87.5, '80-89': 78.89, 'old': 84.32, 'new': 85.98}
2023-10-16 00:35:41,176 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87]
2023-10-16 00:35:41,176 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94]

2023-10-16 00:35:41,177 [trainer.py] => Average Accuracy (CNN): 86.70333333333333
2023-10-16 00:35:41,178 [trainer.py] => All params: 85867777
2023-10-16 00:35:41,179 [trainer.py] => Trainable params: 85867777
2023-10-16 00:35:41,182 [simplecil.py] => Learning on 90-120
2023-10-16 00:44:56,158 [trainer.py] => No NME accuracy.
2023-10-16 00:44:56,158 [trainer.py] => CNN: {'total': 81.54, '00-09': 79.5, '10-19': 81.0, '20-29': 75.0, '30-39': 86.5, '40-49': 85.0, '50-59': 85.43, '60-69': 87.0, '70-79': 85.5, '80-89': 75.88, '90-99': 79.9, '100-109': 79.4, '110-119': 78.39, 'old': 82.31, 'new': 79.23}
2023-10-16 00:44:56,158 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54]
2023-10-16 00:44:56,158 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12]

2023-10-16 00:44:56,158 [trainer.py] => Average Accuracy (CNN): 85.41250000000001
2023-10-16 00:44:56,158 [trainer.py] => All params: 85890817
2023-10-16 00:44:56,158 [trainer.py] => Trainable params: 85890817
2023-10-16 00:44:56,174 [simplecil.py] => Learning on 120-150
2023-10-16 00:54:09,722 [trainer.py] => No NME accuracy.
2023-10-16 00:54:09,722 [trainer.py] => CNN: {'total': 79.29, '00-09': 76.5, '10-19': 80.0, '20-29': 73.0, '30-39': 86.0, '40-49': 82.5, '50-59': 78.89, '60-69': 82.0, '70-79': 85.0, '80-89': 73.87, '90-99': 78.39, '100-109': 76.88, '110-119': 72.86, '120-129': 83.5, '130-139': 80.0, '140-149': 79.9, 'old': 78.83, 'new': 81.14}
2023-10-16 00:54:09,722 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29]
2023-10-16 00:54:09,722 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86]

2023-10-16 00:54:09,738 [trainer.py] => Average Accuracy (CNN): 84.18800000000002
2023-10-16 00:54:09,738 [trainer.py] => All params: 85913857
2023-10-16 00:54:09,738 [trainer.py] => Trainable params: 85913857
2023-10-16 00:54:09,738 [simplecil.py] => Learning on 150-180
2023-10-16 01:03:36,985 [trainer.py] => No NME accuracy.
2023-10-16 01:03:36,985 [trainer.py] => CNN: {'total': 76.78, '00-09': 75.0, '10-19': 76.0, '20-29': 71.5, '30-39': 82.5, '40-49': 78.0, '50-59': 76.88, '60-69': 82.5, '70-79': 83.5, '80-89': 70.85, '90-99': 78.89, '100-109': 74.37, '110-119': 70.35, '120-129': 83.5, '130-139': 80.5, '140-149': 76.88, '150-159': 79.9, '160-169': 73.87, '170-179': 67.0, 'old': 77.42, 'new': 73.58}
2023-10-16 01:03:36,985 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29, 76.78]
2023-10-16 01:03:36,985 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86, 93.35]

2023-10-16 01:03:36,985 [trainer.py] => Average Accuracy (CNN): 82.95333333333333
2023-10-16 01:03:36,985 [trainer.py] => All params: 85936897
2023-10-16 01:03:36,985 [trainer.py] => Trainable params: 85936897
2023-10-16 01:03:37,002 [simplecil.py] => Learning on 180-210
2023-10-16 01:13:22,054 [trainer.py] => No NME accuracy.
2023-10-16 01:13:22,055 [trainer.py] => CNN: {'total': 75.67, '00-09': 74.0, '10-19': 76.5, '20-29': 69.5, '30-39': 83.0, '40-49': 77.5, '50-59': 75.88, '60-69': 79.5, '70-79': 82.5, '80-89': 70.35, '90-99': 76.38, '100-109': 75.38, '110-119': 68.34, '120-129': 84.0, '130-139': 78.0, '140-149': 75.88, '150-159': 77.39, '160-169': 73.37, '170-179': 67.5, '180-189': 72.22, '190-199': 81.5, '200-209': 70.35, 'old': 75.84, 'new': 74.71}
2023-10-16 01:13:22,055 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29, 76.78, 75.67]
2023-10-16 01:13:22,055 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86, 93.35, 92.62]

2023-10-16 01:13:22,056 [trainer.py] => Average Accuracy (CNN): 81.91285714285713
2023-10-16 01:13:22,056 [trainer.py] => All params: 85959937
2023-10-16 01:13:22,057 [trainer.py] => Trainable params: 85959937
2023-10-16 01:13:22,061 [simplecil.py] => Learning on 210-240
2023-10-16 01:24:02,580 [trainer.py] => No NME accuracy.
2023-10-16 01:24:02,581 [trainer.py] => CNN: {'total': 74.06, '00-09': 73.5, '10-19': 73.5, '20-29': 69.0, '30-39': 83.5, '40-49': 75.5, '50-59': 77.39, '60-69': 79.0, '70-79': 81.5, '80-89': 70.85, '90-99': 75.88, '100-109': 66.33, '110-119': 67.84, '120-129': 81.5, '130-139': 78.5, '140-149': 75.38, '150-159': 75.88, '160-169': 72.36, '170-179': 62.5, '180-189': 71.72, '190-199': 81.5, '200-209': 66.83, '210-219': 50.0, '220-229': 87.44, '230-239': 80.0, 'old': 74.29, 'new': 72.45}
2023-10-16 01:24:02,581 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29, 76.78, 75.67, 74.06]
2023-10-16 01:24:02,583 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86, 93.35, 92.62, 91.29]

2023-10-16 01:24:02,583 [trainer.py] => Average Accuracy (CNN): 80.93125
2023-10-16 01:24:02,584 [trainer.py] => All params: 85982977
2023-10-16 01:24:02,584 [trainer.py] => Trainable params: 85982977
2023-10-16 01:24:02,584 [simplecil.py] => Learning on 240-270
2023-10-16 01:34:50,146 [trainer.py] => No NME accuracy.
2023-10-16 01:34:50,147 [trainer.py] => CNN: {'total': 73.21, '00-09': 72.5, '10-19': 73.0, '20-29': 69.0, '30-39': 82.0, '40-49': 75.5, '50-59': 75.38, '60-69': 78.0, '70-79': 81.0, '80-89': 69.85, '90-99': 74.87, '100-109': 66.83, '110-119': 64.32, '120-129': 75.5, '130-139': 77.0, '140-149': 73.37, '150-159': 72.36, '160-169': 72.36, '170-179': 64.5, '180-189': 71.72, '190-199': 79.5, '200-209': 61.31, '210-219': 50.5, '220-229': 86.93, '230-239': 80.5, '240-249': 69.0, '250-259': 77.39, '260-269': 82.5, 'old': 72.83, 'new': 76.29}
2023-10-16 01:34:50,148 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29, 76.78, 75.67, 74.06, 73.21]
2023-10-16 01:34:50,148 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86, 93.35, 92.62, 91.29, 91.29]

2023-10-16 01:34:50,148 [trainer.py] => Average Accuracy (CNN): 80.07333333333334
2023-10-16 01:34:50,149 [trainer.py] => All params: 86006017
2023-10-16 01:34:50,150 [trainer.py] => Trainable params: 86006017
2023-10-16 01:34:50,158 [simplecil.py] => Learning on 270-300
2023-10-16 01:45:36,437 [trainer.py] => No NME accuracy.
2023-10-16 01:45:36,437 [trainer.py] => CNN: {'total': 73.45, '00-09': 72.0, '10-19': 75.0, '20-29': 68.0, '30-39': 83.0, '40-49': 72.5, '50-59': 76.88, '60-69': 76.0, '70-79': 82.0, '80-89': 70.35, '90-99': 71.36, '100-109': 65.83, '110-119': 63.32, '120-129': 77.5, '130-139': 76.5, '140-149': 73.37, '150-159': 71.86, '160-169': 70.85, '170-179': 64.5, '180-189': 70.2, '190-199': 78.0, '200-209': 63.82, '210-219': 50.0, '220-229': 87.44, '230-239': 80.0, '240-249': 66.0, '250-259': 75.88, '260-269': 81.0, '270-279': 76.88, '280-289': 82.5, '290-299': 80.9, 'old': 72.71, 'new': 80.1}
2023-10-16 01:45:36,437 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87, 81.54, 79.29, 76.78, 75.67, 74.06, 73.21, 73.45]
2023-10-16 01:45:36,437 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94, 96.12, 94.86, 93.35, 92.62, 91.29, 91.29, 91.31]

2023-10-16 01:45:36,446 [trainer.py] => Average Accuracy (CNN): 79.41100000000002
2023-10-16 02:40:17,575 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 02:40:17,575 [trainer.py] => prefix:  
2023-10-16 02:40:17,576 [trainer.py] => dataset: omnibenchmark
2023-10-16 02:40:17,576 [trainer.py] => memory_size: 0
2023-10-16 02:40:17,576 [trainer.py] => memory_per_class: 0
2023-10-16 02:40:17,576 [trainer.py] => fixed_memory: False
2023-10-16 02:40:17,576 [trainer.py] => shuffle: True
2023-10-16 02:40:17,576 [trainer.py] => init_cls: 30
2023-10-16 02:40:17,576 [trainer.py] => increment: 30
2023-10-16 02:40:17,577 [trainer.py] => model_name: simplecil
2023-10-16 02:40:17,577 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 02:40:17,577 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 02:40:17,578 [trainer.py] => seed: 1993
2023-10-16 02:40:17,578 [trainer.py] => tuned_epoch: 0
2023-10-16 02:40:17,578 [trainer.py] => init_lr: 0.01
2023-10-16 02:40:17,579 [trainer.py] => batch_size: 256
2023-10-16 02:40:17,579 [trainer.py] => weight_decay: 0.0005
2023-10-16 02:40:17,579 [trainer.py] => min_lr: 1e-08
2023-10-16 02:40:17,579 [trainer.py] => optimizer: sgd
2023-10-16 02:40:17,580 [trainer.py] => vpt_type: shallow
2023-10-16 02:40:17,580 [trainer.py] => prompt_token_num: 3
2023-10-16 02:40:18,641 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 02:41:17,125 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 02:41:17,125 [trainer.py] => prefix:  
2023-10-16 02:41:17,126 [trainer.py] => dataset: omnibenchmark
2023-10-16 02:41:17,126 [trainer.py] => memory_size: 0
2023-10-16 02:41:17,126 [trainer.py] => memory_per_class: 0
2023-10-16 02:41:17,126 [trainer.py] => fixed_memory: False
2023-10-16 02:41:17,128 [trainer.py] => shuffle: True
2023-10-16 02:41:17,128 [trainer.py] => init_cls: 30
2023-10-16 02:41:17,129 [trainer.py] => increment: 30
2023-10-16 02:41:17,129 [trainer.py] => model_name: simplecil
2023-10-16 02:41:17,129 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 02:41:17,130 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 02:41:17,130 [trainer.py] => seed: 1993
2023-10-16 02:41:17,130 [trainer.py] => tuned_epoch: 0
2023-10-16 02:41:17,130 [trainer.py] => init_lr: 0.01
2023-10-16 02:41:17,130 [trainer.py] => batch_size: 256
2023-10-16 02:41:17,131 [trainer.py] => weight_decay: 0.0005
2023-10-16 02:41:17,131 [trainer.py] => min_lr: 1e-08
2023-10-16 02:41:17,131 [trainer.py] => optimizer: sgd
2023-10-16 02:41:17,131 [trainer.py] => vpt_type: shallow
2023-10-16 02:41:17,131 [trainer.py] => prompt_token_num: 3
2023-10-16 02:41:17,576 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 02:41:18,864 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 02:41:19,214 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 02:41:19,877 [trainer.py] => All params: 85798656
2023-10-16 02:41:19,879 [trainer.py] => Trainable params: 85798656
2023-10-16 02:41:20,779 [simplecil.py] => Learning on 0-30
2023-10-16 02:49:42,902 [trainer.py] => No NME accuracy.
2023-10-16 02:49:42,903 [trainer.py] => CNN: {'total': 87.5, '00-09': 91.0, '10-19': 89.0, '20-29': 82.5, 'old': 0, 'new': 87.5}
2023-10-16 02:49:42,904 [trainer.py] => CNN top1 curve: [87.5]
2023-10-16 02:49:42,904 [trainer.py] => CNN top5 curve: [98.83]

2023-10-16 02:49:42,905 [trainer.py] => Average Accuracy (CNN): 87.5
2023-10-16 02:49:42,906 [trainer.py] => All params: 85821697
2023-10-16 02:49:42,906 [trainer.py] => Trainable params: 85821697
2023-10-16 02:49:42,928 [simplecil.py] => Learning on 30-60
2023-10-16 02:58:11,798 [trainer.py] => No NME accuracy.
2023-10-16 02:58:11,799 [trainer.py] => CNN: {'total': 87.74, '00-09': 86.0, '10-19': 88.0, '20-29': 80.0, '30-39': 89.5, '40-49': 88.0, '50-59': 94.97, 'old': 84.67, 'new': 90.82}
2023-10-16 02:58:11,800 [trainer.py] => CNN top1 curve: [87.5, 87.74]
2023-10-16 02:58:11,800 [trainer.py] => CNN top5 curve: [98.83, 98.08]

2023-10-16 02:58:11,800 [trainer.py] => Average Accuracy (CNN): 87.62
2023-10-16 02:58:11,801 [trainer.py] => All params: 85844737
2023-10-16 02:58:11,801 [trainer.py] => Trainable params: 85844737
2023-10-16 02:58:11,804 [simplecil.py] => Learning on 60-90
2023-10-16 03:06:56,151 [trainer.py] => No NME accuracy.
2023-10-16 03:06:56,152 [trainer.py] => CNN: {'total': 84.87, '00-09': 81.0, '10-19': 83.0, '20-29': 76.5, '30-39': 87.0, '40-49': 86.0, '50-59': 92.46, '60-69': 91.5, '70-79': 87.5, '80-89': 78.89, 'old': 84.32, 'new': 85.98}
2023-10-16 03:06:56,157 [trainer.py] => CNN top1 curve: [87.5, 87.74, 84.87]
2023-10-16 03:06:56,157 [trainer.py] => CNN top5 curve: [98.83, 98.08, 96.94]

2023-10-16 03:06:56,158 [trainer.py] => Average Accuracy (CNN): 86.70333333333333
2023-10-16 03:06:56,159 [trainer.py] => All params: 85867777
2023-10-16 03:06:56,160 [trainer.py] => Trainable params: 85867777
2023-10-16 03:06:56,167 [simplecil.py] => Learning on 90-120
2023-10-16 03:14:57,189 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 03:14:57,189 [trainer.py] => prefix:  
2023-10-16 03:14:57,189 [trainer.py] => dataset: omnibenchmark
2023-10-16 03:14:57,189 [trainer.py] => memory_size: 0
2023-10-16 03:14:57,190 [trainer.py] => memory_per_class: 0
2023-10-16 03:14:57,190 [trainer.py] => fixed_memory: False
2023-10-16 03:14:57,190 [trainer.py] => shuffle: True
2023-10-16 03:14:57,190 [trainer.py] => init_cls: 30
2023-10-16 03:14:57,191 [trainer.py] => increment: 30
2023-10-16 03:14:57,191 [trainer.py] => model_name: simplecil
2023-10-16 03:14:57,191 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 03:14:57,191 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 03:14:57,191 [trainer.py] => seed: 1993
2023-10-16 03:14:57,191 [trainer.py] => tuned_epoch: 0
2023-10-16 03:14:57,191 [trainer.py] => init_lr: 0.01
2023-10-16 03:14:57,192 [trainer.py] => batch_size: 256
2023-10-16 03:14:57,192 [trainer.py] => weight_decay: 0.0005
2023-10-16 03:14:57,192 [trainer.py] => min_lr: 1e-08
2023-10-16 03:14:57,192 [trainer.py] => optimizer: sgd
2023-10-16 03:14:57,192 [trainer.py] => vpt_type: shallow
2023-10-16 03:14:57,192 [trainer.py] => prompt_token_num: 3
2023-10-16 03:14:58,045 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 03:14:59,419 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 03:14:59,829 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 03:15:00,599 [trainer.py] => All params: 85798656
2023-10-16 03:15:00,601 [trainer.py] => Trainable params: 85798656
2023-10-16 03:15:01,078 [simplecil.py] => Learning on 0-30
2023-10-16 03:22:37,458 [trainer.py] => No NME accuracy.
2023-10-16 03:22:37,459 [trainer.py] => CNN: {'total': 87.17, '00-09': 90.5, '10-19': 87.5, '20-29': 83.5, 'old': 0, 'new': 87.17}
2023-10-16 03:22:37,459 [trainer.py] => CNN top1 curve: [87.17]
2023-10-16 03:22:37,459 [trainer.py] => CNN top5 curve: [98.5]

2023-10-16 03:22:37,460 [trainer.py] => Average Accuracy (CNN): 87.17
2023-10-16 03:22:37,460 [trainer.py] => All params: 85821697
2023-10-16 03:22:37,462 [trainer.py] => Trainable params: 85821697
2023-10-16 03:22:37,468 [simplecil.py] => Learning on 30-60
2023-10-16 03:30:34,726 [trainer.py] => No NME accuracy.
2023-10-16 03:30:34,726 [trainer.py] => CNN: {'total': 78.82, '00-09': 64.5, '10-19': 73.0, '20-29': 52.0, '30-39': 92.0, '40-49': 95.5, '50-59': 95.98, 'old': 63.17, 'new': 94.49}
2023-10-16 03:30:34,726 [trainer.py] => CNN top1 curve: [87.17, 78.82]
2023-10-16 03:30:34,726 [trainer.py] => CNN top5 curve: [98.5, 96.75]

2023-10-16 03:30:34,726 [trainer.py] => Average Accuracy (CNN): 82.995
2023-10-16 03:30:34,726 [trainer.py] => All params: 85844737
2023-10-16 03:30:34,726 [trainer.py] => Trainable params: 85844737
2023-10-16 03:30:34,726 [simplecil.py] => Learning on 60-90
2023-10-16 03:38:43,997 [trainer.py] => No NME accuracy.
2023-10-16 03:38:43,997 [trainer.py] => CNN: {'total': 70.36, '00-09': 43.5, '10-19': 43.0, '20-29': 42.0, '30-39': 70.0, '40-49': 72.0, '50-59': 83.92, '60-69': 96.0, '70-79': 94.0, '80-89': 88.94, 'old': 59.05, 'new': 92.99}
2023-10-16 03:38:43,997 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36]
2023-10-16 03:38:43,997 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04]

2023-10-16 03:38:43,997 [trainer.py] => Average Accuracy (CNN): 78.78333333333335
2023-10-16 03:38:43,997 [trainer.py] => All params: 85867777
2023-10-16 03:38:43,997 [trainer.py] => Trainable params: 85867777
2023-10-16 03:38:44,012 [simplecil.py] => Learning on 90-120
2023-10-16 03:47:28,548 [trainer.py] => No NME accuracy.
2023-10-16 03:47:28,548 [trainer.py] => CNN: {'total': 54.45, '00-09': 10.5, '10-19': 9.0, '20-29': 9.0, '30-39': 46.5, '40-49': 42.5, '50-59': 57.29, '60-69': 64.5, '70-79': 73.0, '80-89': 66.33, '90-99': 91.96, '100-109': 92.46, '110-119': 90.95, 'old': 42.05, 'new': 91.79}
2023-10-16 03:47:28,548 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45]
2023-10-16 03:47:28,548 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74]

2023-10-16 03:47:28,548 [trainer.py] => Average Accuracy (CNN): 72.7
2023-10-16 03:47:28,551 [trainer.py] => All params: 85890817
2023-10-16 03:47:28,551 [trainer.py] => Trainable params: 85890817
2023-10-16 03:47:28,551 [simplecil.py] => Learning on 120-150
2023-10-16 03:56:37,833 [trainer.py] => No NME accuracy.
2023-10-16 03:56:37,833 [trainer.py] => CNN: {'total': 42.32, '00-09': 0.0, '10-19': 1.0, '20-29': 0.0, '30-39': 17.5, '40-49': 3.0, '50-59': 20.1, '60-69': 29.5, '70-79': 45.0, '80-89': 36.18, '90-99': 79.4, '100-109': 68.84, '110-119': 60.3, '120-129': 92.0, '130-139': 93.0, '140-149': 89.45, 'old': 30.02, 'new': 91.49}
2023-10-16 03:56:37,833 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32]
2023-10-16 03:56:37,833 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12]

2023-10-16 03:56:37,840 [trainer.py] => Average Accuracy (CNN): 66.624
2023-10-16 03:56:37,841 [trainer.py] => All params: 85913857
2023-10-16 03:56:37,841 [trainer.py] => Trainable params: 85913857
2023-10-16 03:56:37,841 [simplecil.py] => Learning on 150-180
2023-10-16 04:06:01,164 [trainer.py] => No NME accuracy.
2023-10-16 04:06:01,164 [trainer.py] => CNN: {'total': 36.3, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 4.02, '60-69': 6.0, '70-79': 11.0, '80-89': 2.51, '90-99': 62.81, '100-109': 46.23, '110-119': 27.14, '120-129': 83.0, '130-139': 76.5, '140-149': 72.86, '150-159': 85.93, '160-169': 87.44, '170-179': 88.5, 'old': 26.12, 'new': 87.29}
2023-10-16 04:06:01,164 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32, 36.3]
2023-10-16 04:06:01,164 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12, 49.53]

2023-10-16 04:06:01,164 [trainer.py] => Average Accuracy (CNN): 61.57
2023-10-16 04:06:01,164 [trainer.py] => All params: 85936897
2023-10-16 04:06:01,164 [trainer.py] => Trainable params: 85936897
2023-10-16 04:06:01,180 [simplecil.py] => Learning on 180-210
2023-10-16 04:15:59,813 [trainer.py] => No NME accuracy.
2023-10-16 04:15:59,813 [trainer.py] => CNN: {'total': 32.54, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 0.5, '70-79': 0.5, '80-89': 0.5, '90-99': 19.6, '100-109': 13.57, '110-119': 4.02, '120-129': 55.0, '130-139': 60.0, '140-149': 61.31, '150-159': 68.84, '160-169': 58.79, '170-179': 69.0, '180-189': 93.94, '190-199': 93.0, '200-209': 85.43, 'old': 22.86, 'new': 90.79}
2023-10-16 04:15:59,813 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32, 36.3, 32.54]
2023-10-16 04:15:59,813 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12, 49.53, 44.04]

2023-10-16 04:15:59,813 [trainer.py] => Average Accuracy (CNN): 57.42285714285715
2023-10-16 04:15:59,813 [trainer.py] => All params: 85959937
2023-10-16 04:15:59,813 [trainer.py] => Trainable params: 85959937
2023-10-16 04:15:59,813 [simplecil.py] => Learning on 210-240
2023-10-16 04:26:55,101 [trainer.py] => No NME accuracy.
2023-10-16 04:26:55,104 [trainer.py] => CNN: {'total': 27.49, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 0.0, '70-79': 0.0, '80-89': 0.0, '90-99': 0.5, '100-109': 1.01, '110-119': 0.0, '120-129': 12.5, '130-139': 24.0, '140-149': 20.6, '150-159': 63.82, '160-169': 44.72, '170-179': 21.5, '180-189': 70.2, '190-199': 82.5, '200-209': 56.78, '210-219': 73.0, '220-229': 97.99, '230-239': 91.0, 'old': 18.93, 'new': 87.31}
2023-10-16 04:26:55,105 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32, 36.3, 32.54, 27.49]
2023-10-16 04:26:55,105 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12, 49.53, 44.04, 38.1]

2023-10-16 04:26:55,107 [trainer.py] => Average Accuracy (CNN): 53.681250000000006
2023-10-16 04:26:55,107 [trainer.py] => All params: 85982977
2023-10-16 04:26:55,107 [trainer.py] => Trainable params: 85982977
2023-10-16 04:26:55,116 [simplecil.py] => Learning on 240-270
2023-10-16 04:38:35,075 [trainer.py] => No NME accuracy.
2023-10-16 04:38:35,075 [trainer.py] => CNN: {'total': 25.97, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 0.0, '70-79': 0.0, '80-89': 0.0, '90-99': 0.0, '100-109': 0.0, '110-119': 0.0, '120-129': 0.0, '130-139': 0.0, '140-149': 1.01, '150-159': 21.11, '160-169': 21.61, '170-179': 1.5, '180-189': 55.05, '190-199': 59.0, '200-209': 36.18, '210-219': 62.5, '220-229': 78.89, '230-239': 80.5, '240-249': 91.0, '250-259': 94.97, '260-269': 98.0, 'old': 17.38, 'new': 94.66}
2023-10-16 04:38:35,075 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32, 36.3, 32.54, 27.49, 25.97]
2023-10-16 04:38:35,075 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12, 49.53, 44.04, 38.1, 35.29]

2023-10-16 04:38:35,075 [trainer.py] => Average Accuracy (CNN): 50.60222222222223
2023-10-16 04:38:35,075 [trainer.py] => All params: 86006017
2023-10-16 04:38:35,075 [trainer.py] => Trainable params: 86006017
2023-10-16 04:38:35,091 [simplecil.py] => Learning on 270-300
2023-10-16 04:50:13,702 [trainer.py] => No NME accuracy.
2023-10-16 04:50:13,702 [trainer.py] => CNN: {'total': 24.28, '00-09': 0.0, '10-19': 0.0, '20-29': 0.0, '30-39': 0.0, '40-49': 0.0, '50-59': 0.0, '60-69': 0.0, '70-79': 0.0, '80-89': 0.0, '90-99': 0.0, '100-109': 0.0, '110-119': 0.0, '120-129': 0.0, '130-139': 0.0, '140-149': 0.0, '150-159': 5.03, '160-169': 0.0, '170-179': 0.0, '180-189': 18.69, '190-199': 19.0, '200-209': 10.05, '210-219': 25.0, '220-229': 71.36, '230-239': 60.5, '240-249': 69.0, '250-259': 79.4, '260-269': 86.5, '270-279': 97.49, '280-289': 91.0, '290-299': 95.48, 'old': 16.47, 'new': 94.65}
2023-10-16 04:50:13,702 [trainer.py] => CNN top1 curve: [87.17, 78.82, 70.36, 54.45, 42.32, 36.3, 32.54, 27.49, 25.97, 24.28]
2023-10-16 04:50:13,702 [trainer.py] => CNN top5 curve: [98.5, 96.75, 87.04, 75.74, 61.12, 49.53, 44.04, 38.1, 35.29, 33.98]

2023-10-16 04:50:13,702 [trainer.py] => Average Accuracy (CNN): 47.970000000000006
2023-10-16 05:45:01,966 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 05:45:01,967 [trainer.py] => prefix:  
2023-10-16 05:45:01,967 [trainer.py] => dataset: omnibenchmark
2023-10-16 05:45:01,967 [trainer.py] => memory_size: 0
2023-10-16 05:45:01,967 [trainer.py] => memory_per_class: 0
2023-10-16 05:45:01,968 [trainer.py] => fixed_memory: False
2023-10-16 05:45:01,968 [trainer.py] => shuffle: True
2023-10-16 05:45:01,968 [trainer.py] => init_cls: 30
2023-10-16 05:45:01,968 [trainer.py] => increment: 30
2023-10-16 05:45:01,968 [trainer.py] => model_name: simplecil
2023-10-16 05:45:01,969 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 05:45:01,969 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 05:45:01,969 [trainer.py] => seed: 1993
2023-10-16 05:45:01,969 [trainer.py] => tuned_epoch: 0
2023-10-16 05:45:01,969 [trainer.py] => init_lr: 0.01
2023-10-16 05:45:01,970 [trainer.py] => batch_size: 256
2023-10-16 05:45:01,970 [trainer.py] => weight_decay: 0.0005
2023-10-16 05:45:01,970 [trainer.py] => min_lr: 1e-08
2023-10-16 05:45:01,970 [trainer.py] => optimizer: sgd
2023-10-16 05:45:01,970 [trainer.py] => vpt_type: shallow
2023-10-16 05:45:01,970 [trainer.py] => prompt_token_num: 3
2023-10-16 05:45:02,961 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 05:45:04,418 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 05:45:04,855 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 05:45:05,506 [trainer.py] => All params: 85798656
2023-10-16 05:45:05,507 [trainer.py] => Trainable params: 85798656
2023-10-16 05:45:05,979 [simplecil.py] => Learning on 0-30
2023-10-16 05:50:48,818 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 05:50:48,819 [trainer.py] => prefix:  
2023-10-16 05:50:48,819 [trainer.py] => dataset: omnibenchmark
2023-10-16 05:50:48,820 [trainer.py] => memory_size: 0
2023-10-16 05:50:48,820 [trainer.py] => memory_per_class: 0
2023-10-16 05:50:48,820 [trainer.py] => fixed_memory: False
2023-10-16 05:50:48,821 [trainer.py] => shuffle: True
2023-10-16 05:50:48,821 [trainer.py] => init_cls: 30
2023-10-16 05:50:48,821 [trainer.py] => increment: 30
2023-10-16 05:50:48,821 [trainer.py] => model_name: simplecil
2023-10-16 05:50:48,821 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 05:50:48,822 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 05:50:48,822 [trainer.py] => seed: 1993
2023-10-16 05:50:48,822 [trainer.py] => tuned_epoch: 0
2023-10-16 05:50:48,822 [trainer.py] => init_lr: 0.01
2023-10-16 05:50:48,822 [trainer.py] => batch_size: 256
2023-10-16 05:50:48,822 [trainer.py] => weight_decay: 0.0005
2023-10-16 05:50:48,822 [trainer.py] => min_lr: 1e-08
2023-10-16 05:50:48,823 [trainer.py] => optimizer: sgd
2023-10-16 05:50:48,823 [trainer.py] => vpt_type: shallow
2023-10-16 05:50:48,823 [trainer.py] => prompt_token_num: 3
2023-10-16 05:50:49,859 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 05:50:51,261 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 05:50:51,607 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 05:50:52,302 [trainer.py] => All params: 85798656
2023-10-16 05:50:52,303 [trainer.py] => Trainable params: 85798656
2023-10-16 05:50:52,672 [simplecil.py] => Learning on 0-30
2023-10-16 05:51:49,406 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 05:51:49,406 [trainer.py] => prefix:  
2023-10-16 05:51:49,407 [trainer.py] => dataset: omnibenchmark
2023-10-16 05:51:49,407 [trainer.py] => memory_size: 0
2023-10-16 05:51:49,407 [trainer.py] => memory_per_class: 0
2023-10-16 05:51:49,407 [trainer.py] => fixed_memory: False
2023-10-16 05:51:49,408 [trainer.py] => shuffle: True
2023-10-16 05:51:49,408 [trainer.py] => init_cls: 30
2023-10-16 05:51:49,408 [trainer.py] => increment: 30
2023-10-16 05:51:49,409 [trainer.py] => model_name: simplecil
2023-10-16 05:51:49,409 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 05:51:49,409 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 05:51:49,409 [trainer.py] => seed: 1993
2023-10-16 05:51:49,409 [trainer.py] => tuned_epoch: 0
2023-10-16 05:51:49,410 [trainer.py] => init_lr: 0.01
2023-10-16 05:51:49,410 [trainer.py] => batch_size: 256
2023-10-16 05:51:49,410 [trainer.py] => weight_decay: 0.0005
2023-10-16 05:51:49,410 [trainer.py] => min_lr: 1e-08
2023-10-16 05:51:49,410 [trainer.py] => optimizer: sgd
2023-10-16 05:51:49,410 [trainer.py] => vpt_type: shallow
2023-10-16 05:51:49,410 [trainer.py] => prompt_token_num: 3
2023-10-16 05:51:50,279 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 05:51:51,506 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 05:51:51,831 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 05:51:52,463 [trainer.py] => All params: 85798656
2023-10-16 05:51:52,464 [trainer.py] => Trainable params: 85798656
2023-10-16 05:51:52,804 [simplecil.py] => Learning on 0-30
2023-10-16 05:53:07,221 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 05:53:07,222 [trainer.py] => prefix:  
2023-10-16 05:53:07,222 [trainer.py] => dataset: omnibenchmark
2023-10-16 05:53:07,222 [trainer.py] => memory_size: 0
2023-10-16 05:53:07,223 [trainer.py] => memory_per_class: 0
2023-10-16 05:53:07,223 [trainer.py] => fixed_memory: False
2023-10-16 05:53:07,223 [trainer.py] => shuffle: True
2023-10-16 05:53:07,223 [trainer.py] => init_cls: 30
2023-10-16 05:53:07,223 [trainer.py] => increment: 30
2023-10-16 05:53:07,224 [trainer.py] => model_name: simplecil
2023-10-16 05:53:07,224 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 05:53:07,224 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 05:53:07,224 [trainer.py] => seed: 1993
2023-10-16 05:53:07,224 [trainer.py] => tuned_epoch: 0
2023-10-16 05:53:07,224 [trainer.py] => init_lr: 0.01
2023-10-16 05:53:07,224 [trainer.py] => batch_size: 256
2023-10-16 05:53:07,224 [trainer.py] => weight_decay: 0.0005
2023-10-16 05:53:07,224 [trainer.py] => min_lr: 1e-08
2023-10-16 05:53:07,224 [trainer.py] => optimizer: sgd
2023-10-16 05:53:07,225 [trainer.py] => vpt_type: shallow
2023-10-16 05:53:07,225 [trainer.py] => prompt_token_num: 3
2023-10-16 05:53:08,117 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 05:53:09,368 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 05:53:09,725 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 05:53:10,370 [trainer.py] => All params: 85798656
2023-10-16 05:53:10,370 [trainer.py] => Trainable params: 85798656
2023-10-16 05:53:10,725 [simplecil.py] => Learning on 0-30
2023-10-16 05:59:51,428 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 05:59:51,428 [trainer.py] => prefix:  
2023-10-16 05:59:51,428 [trainer.py] => dataset: omnibenchmark
2023-10-16 05:59:51,429 [trainer.py] => memory_size: 0
2023-10-16 05:59:51,429 [trainer.py] => memory_per_class: 0
2023-10-16 05:59:51,430 [trainer.py] => fixed_memory: False
2023-10-16 05:59:51,430 [trainer.py] => shuffle: True
2023-10-16 05:59:51,430 [trainer.py] => init_cls: 30
2023-10-16 05:59:51,431 [trainer.py] => increment: 30
2023-10-16 05:59:51,431 [trainer.py] => model_name: simplecil
2023-10-16 05:59:51,431 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 05:59:51,431 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 05:59:51,431 [trainer.py] => seed: 1993
2023-10-16 05:59:51,432 [trainer.py] => tuned_epoch: 0
2023-10-16 05:59:51,432 [trainer.py] => init_lr: 0.01
2023-10-16 05:59:51,432 [trainer.py] => batch_size: 256
2023-10-16 05:59:51,432 [trainer.py] => weight_decay: 0.0005
2023-10-16 05:59:51,432 [trainer.py] => min_lr: 1e-08
2023-10-16 05:59:51,432 [trainer.py] => optimizer: sgd
2023-10-16 05:59:51,432 [trainer.py] => vpt_type: shallow
2023-10-16 05:59:51,432 [trainer.py] => prompt_token_num: 3
2023-10-16 05:59:52,325 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 05:59:53,554 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 05:59:53,906 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 05:59:54,281 [trainer.py] => All params: 85798656
2023-10-16 05:59:54,282 [trainer.py] => Trainable params: 85798656
2023-10-16 05:59:54,621 [simplecil.py] => Learning on 0-30
2023-10-16 06:04:25,507 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:04:25,508 [trainer.py] => prefix:  
2023-10-16 06:04:25,508 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:04:25,508 [trainer.py] => memory_size: 0
2023-10-16 06:04:25,509 [trainer.py] => memory_per_class: 0
2023-10-16 06:04:25,509 [trainer.py] => fixed_memory: False
2023-10-16 06:04:25,509 [trainer.py] => shuffle: True
2023-10-16 06:04:25,509 [trainer.py] => init_cls: 30
2023-10-16 06:04:25,510 [trainer.py] => increment: 30
2023-10-16 06:04:25,510 [trainer.py] => model_name: simplecil
2023-10-16 06:04:25,510 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:04:25,510 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:04:25,510 [trainer.py] => seed: 1993
2023-10-16 06:04:25,510 [trainer.py] => tuned_epoch: 0
2023-10-16 06:04:25,510 [trainer.py] => init_lr: 0.01
2023-10-16 06:04:25,511 [trainer.py] => batch_size: 256
2023-10-16 06:04:25,511 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:04:25,511 [trainer.py] => min_lr: 1e-08
2023-10-16 06:04:25,511 [trainer.py] => optimizer: sgd
2023-10-16 06:04:25,511 [trainer.py] => vpt_type: shallow
2023-10-16 06:04:25,511 [trainer.py] => prompt_token_num: 3
2023-10-16 06:04:26,417 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:04:27,648 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:04:28,090 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:04:28,735 [trainer.py] => All params: 85798656
2023-10-16 06:04:28,736 [trainer.py] => Trainable params: 85798656
2023-10-16 06:04:29,100 [simplecil.py] => Learning on 0-30
2023-10-16 06:11:55,474 [trainer.py] => No NME accuracy.
2023-10-16 06:11:55,474 [trainer.py] => CNN: {'total': 87.5, '00-09': 91.0, '10-19': 89.0, '20-29': 82.5, 'old': 0, 'new': 87.5}
2023-10-16 06:11:55,474 [trainer.py] => CNN top1 curve: [87.5]
2023-10-16 06:11:55,475 [trainer.py] => CNN top5 curve: [98.83]

2023-10-16 06:11:55,475 [trainer.py] => Average Accuracy (CNN): 87.5
2023-10-16 06:11:55,476 [trainer.py] => All params: 85821697
2023-10-16 06:11:55,477 [trainer.py] => Trainable params: 85821697
2023-10-16 06:11:55,487 [simplecil.py] => Learning on 30-60
2023-10-16 06:32:48,291 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:32:48,292 [trainer.py] => prefix:  
2023-10-16 06:32:48,292 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:32:48,292 [trainer.py] => memory_size: 0
2023-10-16 06:32:48,292 [trainer.py] => memory_per_class: 0
2023-10-16 06:32:48,293 [trainer.py] => fixed_memory: False
2023-10-16 06:32:48,293 [trainer.py] => shuffle: True
2023-10-16 06:32:48,293 [trainer.py] => init_cls: 30
2023-10-16 06:32:48,293 [trainer.py] => increment: 30
2023-10-16 06:32:48,293 [trainer.py] => model_name: simplecil
2023-10-16 06:32:48,294 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:32:48,294 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:32:48,294 [trainer.py] => seed: 1993
2023-10-16 06:32:48,294 [trainer.py] => tuned_epoch: 0
2023-10-16 06:32:48,294 [trainer.py] => init_lr: 0.01
2023-10-16 06:32:48,294 [trainer.py] => batch_size: 256
2023-10-16 06:32:48,294 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:32:48,294 [trainer.py] => min_lr: 1e-08
2023-10-16 06:32:48,294 [trainer.py] => optimizer: sgd
2023-10-16 06:32:48,295 [trainer.py] => vpt_type: shallow
2023-10-16 06:32:48,295 [trainer.py] => prompt_token_num: 3
2023-10-16 06:32:49,165 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:32:50,770 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:32:51,161 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:32:51,795 [trainer.py] => All params: 85798656
2023-10-16 06:32:51,797 [trainer.py] => Trainable params: 85798656
2023-10-16 06:32:52,200 [simplecil.py] => Learning on 0-30
2023-10-16 06:33:25,534 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:33:25,535 [trainer.py] => prefix:  
2023-10-16 06:33:25,535 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:33:25,535 [trainer.py] => memory_size: 0
2023-10-16 06:33:25,536 [trainer.py] => memory_per_class: 0
2023-10-16 06:33:25,536 [trainer.py] => fixed_memory: False
2023-10-16 06:33:25,536 [trainer.py] => shuffle: True
2023-10-16 06:33:25,536 [trainer.py] => init_cls: 30
2023-10-16 06:33:25,536 [trainer.py] => increment: 30
2023-10-16 06:33:25,537 [trainer.py] => model_name: simplecil
2023-10-16 06:33:25,537 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:33:25,537 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:33:25,537 [trainer.py] => seed: 1993
2023-10-16 06:33:25,537 [trainer.py] => tuned_epoch: 0
2023-10-16 06:33:25,537 [trainer.py] => init_lr: 0.01
2023-10-16 06:33:25,537 [trainer.py] => batch_size: 256
2023-10-16 06:33:25,537 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:33:25,537 [trainer.py] => min_lr: 1e-08
2023-10-16 06:33:25,537 [trainer.py] => optimizer: sgd
2023-10-16 06:33:25,537 [trainer.py] => vpt_type: shallow
2023-10-16 06:33:25,538 [trainer.py] => prompt_token_num: 3
2023-10-16 06:33:25,862 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:33:27,303 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:33:27,625 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:33:27,741 [trainer.py] => All params: 85798656
2023-10-16 06:33:27,742 [trainer.py] => Trainable params: 85798656
2023-10-16 06:33:28,083 [simplecil.py] => Learning on 0-30
2023-10-16 06:36:02,268 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:36:02,269 [trainer.py] => prefix:  
2023-10-16 06:36:02,269 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:36:02,269 [trainer.py] => memory_size: 0
2023-10-16 06:36:02,270 [trainer.py] => memory_per_class: 0
2023-10-16 06:36:02,270 [trainer.py] => fixed_memory: False
2023-10-16 06:36:02,270 [trainer.py] => shuffle: True
2023-10-16 06:36:02,272 [trainer.py] => init_cls: 30
2023-10-16 06:36:02,272 [trainer.py] => increment: 30
2023-10-16 06:36:02,272 [trainer.py] => model_name: simplecil
2023-10-16 06:36:02,272 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:36:02,272 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:36:02,272 [trainer.py] => seed: 1993
2023-10-16 06:36:02,272 [trainer.py] => tuned_epoch: 0
2023-10-16 06:36:02,272 [trainer.py] => init_lr: 0.01
2023-10-16 06:36:02,272 [trainer.py] => batch_size: 256
2023-10-16 06:36:02,273 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:36:02,273 [trainer.py] => min_lr: 1e-08
2023-10-16 06:36:02,273 [trainer.py] => optimizer: sgd
2023-10-16 06:36:02,273 [trainer.py] => vpt_type: shallow
2023-10-16 06:36:02,273 [trainer.py] => prompt_token_num: 3
2023-10-16 06:36:02,594 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:36:04,040 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:36:04,380 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:36:04,486 [trainer.py] => All params: 85798656
2023-10-16 06:36:04,487 [trainer.py] => Trainable params: 85798656
2023-10-16 06:36:04,847 [simplecil.py] => Learning on 0-30
2023-10-16 06:37:17,533 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:37:17,533 [trainer.py] => prefix:  
2023-10-16 06:37:17,534 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:37:17,534 [trainer.py] => memory_size: 0
2023-10-16 06:37:17,534 [trainer.py] => memory_per_class: 0
2023-10-16 06:37:17,534 [trainer.py] => fixed_memory: False
2023-10-16 06:37:17,534 [trainer.py] => shuffle: True
2023-10-16 06:37:17,535 [trainer.py] => init_cls: 30
2023-10-16 06:37:17,535 [trainer.py] => increment: 30
2023-10-16 06:37:17,535 [trainer.py] => model_name: simplecil
2023-10-16 06:37:17,535 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:37:17,535 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:37:17,535 [trainer.py] => seed: 1993
2023-10-16 06:37:17,536 [trainer.py] => tuned_epoch: 0
2023-10-16 06:37:17,536 [trainer.py] => init_lr: 0.01
2023-10-16 06:37:17,536 [trainer.py] => batch_size: 256
2023-10-16 06:37:17,536 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:37:17,536 [trainer.py] => min_lr: 1e-08
2023-10-16 06:37:17,536 [trainer.py] => optimizer: sgd
2023-10-16 06:37:17,536 [trainer.py] => vpt_type: shallow
2023-10-16 06:37:17,537 [trainer.py] => prompt_token_num: 3
2023-10-16 06:37:17,886 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:37:19,606 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:37:19,986 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:37:20,106 [trainer.py] => All params: 85798656
2023-10-16 06:37:20,107 [trainer.py] => Trainable params: 85798656
2023-10-16 06:37:20,626 [simplecil.py] => Learning on 0-30
2023-10-16 06:43:12,001 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:43:12,001 [trainer.py] => prefix:  
2023-10-16 06:43:12,001 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:43:12,001 [trainer.py] => memory_size: 0
2023-10-16 06:43:12,001 [trainer.py] => memory_per_class: 0
2023-10-16 06:43:12,001 [trainer.py] => fixed_memory: False
2023-10-16 06:43:12,001 [trainer.py] => shuffle: True
2023-10-16 06:43:12,001 [trainer.py] => init_cls: 30
2023-10-16 06:43:12,001 [trainer.py] => increment: 30
2023-10-16 06:43:12,001 [trainer.py] => model_name: simplecil
2023-10-16 06:43:12,001 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:43:12,002 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:43:12,002 [trainer.py] => seed: 1993
2023-10-16 06:43:12,002 [trainer.py] => tuned_epoch: 0
2023-10-16 06:43:12,002 [trainer.py] => init_lr: 0.01
2023-10-16 06:43:12,003 [trainer.py] => batch_size: 256
2023-10-16 06:43:12,003 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:43:12,003 [trainer.py] => min_lr: 1e-08
2023-10-16 06:43:12,003 [trainer.py] => optimizer: sgd
2023-10-16 06:43:12,003 [trainer.py] => vpt_type: shallow
2023-10-16 06:43:12,003 [trainer.py] => prompt_token_num: 3
2023-10-16 06:43:13,052 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:43:15,278 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:43:15,920 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:43:16,597 [trainer.py] => All params: 85798656
2023-10-16 06:43:16,598 [trainer.py] => Trainable params: 85798656
2023-10-16 06:43:17,067 [simplecil.py] => Learning on 0-30
2023-10-16 06:45:52,365 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:45:52,366 [trainer.py] => prefix:  
2023-10-16 06:45:52,366 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:45:52,366 [trainer.py] => memory_size: 0
2023-10-16 06:45:52,366 [trainer.py] => memory_per_class: 0
2023-10-16 06:45:52,366 [trainer.py] => fixed_memory: False
2023-10-16 06:45:52,367 [trainer.py] => shuffle: True
2023-10-16 06:45:52,367 [trainer.py] => init_cls: 30
2023-10-16 06:45:52,367 [trainer.py] => increment: 30
2023-10-16 06:45:52,367 [trainer.py] => model_name: simplecil
2023-10-16 06:45:52,367 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:45:52,367 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:45:52,367 [trainer.py] => seed: 1993
2023-10-16 06:45:52,368 [trainer.py] => tuned_epoch: 0
2023-10-16 06:45:52,368 [trainer.py] => init_lr: 0.01
2023-10-16 06:45:52,368 [trainer.py] => batch_size: 256
2023-10-16 06:45:52,368 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:45:52,368 [trainer.py] => min_lr: 1e-08
2023-10-16 06:45:52,368 [trainer.py] => optimizer: sgd
2023-10-16 06:45:52,368 [trainer.py] => vpt_type: shallow
2023-10-16 06:45:52,368 [trainer.py] => prompt_token_num: 3
2023-10-16 06:45:53,546 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:45:55,812 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:45:56,216 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:45:56,882 [trainer.py] => All params: 85798656
2023-10-16 06:45:56,883 [trainer.py] => Trainable params: 85798656
2023-10-16 06:45:57,315 [simplecil.py] => Learning on 0-30
2023-10-16 06:47:26,181 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:47:26,182 [trainer.py] => prefix:  
2023-10-16 06:47:26,182 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:47:26,182 [trainer.py] => memory_size: 0
2023-10-16 06:47:26,182 [trainer.py] => memory_per_class: 0
2023-10-16 06:47:26,183 [trainer.py] => fixed_memory: False
2023-10-16 06:47:26,183 [trainer.py] => shuffle: True
2023-10-16 06:47:26,183 [trainer.py] => init_cls: 30
2023-10-16 06:47:26,183 [trainer.py] => increment: 30
2023-10-16 06:47:26,183 [trainer.py] => model_name: simplecil
2023-10-16 06:47:26,184 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:47:26,185 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:47:26,185 [trainer.py] => seed: 1993
2023-10-16 06:47:26,185 [trainer.py] => tuned_epoch: 0
2023-10-16 06:47:26,185 [trainer.py] => init_lr: 0.01
2023-10-16 06:47:26,185 [trainer.py] => batch_size: 256
2023-10-16 06:47:26,185 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:47:26,185 [trainer.py] => min_lr: 1e-08
2023-10-16 06:47:26,185 [trainer.py] => optimizer: sgd
2023-10-16 06:47:26,185 [trainer.py] => vpt_type: shallow
2023-10-16 06:47:26,185 [trainer.py] => prompt_token_num: 3
2023-10-16 06:47:27,252 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 06:47:29,459 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 06:47:29,888 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 06:47:30,539 [trainer.py] => All params: 85798656
2023-10-16 06:47:30,540 [trainer.py] => Trainable params: 85798656
2023-10-16 06:47:30,954 [simplecil.py] => Learning on 0-30
2023-10-16 06:51:01,416 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 06:51:01,417 [trainer.py] => prefix:  
2023-10-16 06:51:01,417 [trainer.py] => dataset: omnibenchmark
2023-10-16 06:51:01,417 [trainer.py] => memory_size: 0
2023-10-16 06:51:01,418 [trainer.py] => memory_per_class: 0
2023-10-16 06:51:01,418 [trainer.py] => fixed_memory: False
2023-10-16 06:51:01,418 [trainer.py] => shuffle: True
2023-10-16 06:51:01,418 [trainer.py] => init_cls: 30
2023-10-16 06:51:01,418 [trainer.py] => increment: 30
2023-10-16 06:51:01,419 [trainer.py] => model_name: simplecil
2023-10-16 06:51:01,419 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 06:51:01,419 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 06:51:01,419 [trainer.py] => seed: 1993
2023-10-16 06:51:01,420 [trainer.py] => tuned_epoch: 0
2023-10-16 06:51:01,420 [trainer.py] => init_lr: 0.01
2023-10-16 06:51:01,420 [trainer.py] => batch_size: 256
2023-10-16 06:51:01,420 [trainer.py] => weight_decay: 0.0005
2023-10-16 06:51:01,420 [trainer.py] => min_lr: 1e-08
2023-10-16 06:51:01,420 [trainer.py] => optimizer: sgd
2023-10-16 06:51:01,420 [trainer.py] => vpt_type: shallow
2023-10-16 06:51:01,421 [trainer.py] => prompt_token_num: 3
2023-10-16 06:51:02,533 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 07:05:56,814 [trainer.py] => config: ./exps/simplecil_omnibenchmark.json
2023-10-16 07:05:56,815 [trainer.py] => prefix:  
2023-10-16 07:05:56,815 [trainer.py] => dataset: omnibenchmark
2023-10-16 07:05:56,815 [trainer.py] => memory_size: 0
2023-10-16 07:05:56,815 [trainer.py] => memory_per_class: 0
2023-10-16 07:05:56,815 [trainer.py] => fixed_memory: False
2023-10-16 07:05:56,815 [trainer.py] => shuffle: True
2023-10-16 07:05:56,815 [trainer.py] => init_cls: 30
2023-10-16 07:05:56,815 [trainer.py] => increment: 30
2023-10-16 07:05:56,815 [trainer.py] => model_name: simplecil
2023-10-16 07:05:56,815 [trainer.py] => convnet_type: pretrained_vit_b16_224_in21k
2023-10-16 07:05:56,816 [trainer.py] => device: [device(type='cuda', index=0)]
2023-10-16 07:05:56,816 [trainer.py] => seed: 1993
2023-10-16 07:05:56,816 [trainer.py] => tuned_epoch: 20
2023-10-16 07:05:56,816 [trainer.py] => init_lr: 0.01
2023-10-16 07:05:56,816 [trainer.py] => batch_size: 256
2023-10-16 07:05:56,816 [trainer.py] => weight_decay: 0.0005
2023-10-16 07:05:56,817 [trainer.py] => min_lr: 1e-08
2023-10-16 07:05:56,817 [trainer.py] => optimizer: sgd
2023-10-16 07:05:56,817 [trainer.py] => vpt_type: shallow
2023-10-16 07:05:56,818 [trainer.py] => prompt_token_num: 3
2023-10-16 07:05:57,146 [data_manager.py] => [169, 221, 146, 296, 92, 229, 49, 70, 126, 77, 243, 57, 120, 223, 27, 217, 154, 8, 101, 182, 54, 50, 97, 162, 28, 193, 79, 6, 151, 0, 173, 187, 44, 277, 157, 16, 257, 122, 35, 9, 171, 176, 134, 4, 87, 255, 112, 153, 246, 286, 147, 186, 107, 98, 10, 7, 266, 214, 36, 165, 139, 254, 103, 269, 59, 23, 298, 39, 73, 208, 135, 299, 102, 20, 12, 268, 11, 209, 161, 210, 74, 42, 56, 99, 235, 133, 159, 189, 145, 238, 215, 241, 138, 195, 233, 279, 88, 199, 64, 280, 26, 203, 17, 245, 174, 236, 137, 252, 80, 68, 181, 150, 118, 94, 75, 2, 109, 119, 232, 15, 69, 184, 201, 261, 55, 287, 273, 66, 175, 32, 142, 136, 116, 76, 179, 1, 91, 248, 275, 240, 290, 170, 132, 106, 265, 270, 85, 19, 284, 43, 259, 293, 228, 200, 104, 227, 51, 224, 163, 297, 216, 260, 93, 46, 100, 272, 105, 72, 131, 3, 156, 256, 249, 48, 113, 82, 172, 213, 62, 53, 271, 168, 253, 226, 183, 180, 276, 283, 78, 61, 143, 278, 30, 141, 196, 264, 231, 52, 222, 40, 125, 219, 65, 166, 192, 289, 45, 205, 89, 267, 90, 71, 167, 262, 281, 212, 96, 84, 127, 67, 294, 178, 288, 197, 21, 18, 111, 108, 58, 230, 188, 31, 110, 291, 129, 24, 204, 83, 81, 251, 60, 13, 128, 14, 86, 63, 117, 198, 274, 5, 22, 144, 258, 121, 38, 207, 148, 292, 41, 234, 237, 114, 202, 37, 149, 206, 155, 29, 130, 177, 194, 152, 34, 33, 239, 160, 140, 47, 244, 25, 282, 158, 211, 123, 190, 218, 164, 247, 263, 191, 220, 115, 242, 250, 124, 295, 95, 285, 225, 185]
2023-10-16 07:05:59,402 [_builder.py] => Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.augreg_in21k)
2023-10-16 07:05:59,875 [_hub.py] => [timm/vit_base_patch16_224.augreg_in21k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2023-10-16 07:06:00,538 [trainer.py] => All params: 85798656
2023-10-16 07:06:00,539 [trainer.py] => Trainable params: 85798656
2023-10-16 07:06:00,982 [simplecil.py] => Learning on 0-30
